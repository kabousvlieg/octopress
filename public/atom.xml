<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Kobus' musings]]></title>
  <link href="http://embeddedfool.net/atom.xml" rel="self"/>
  <link href="http://embeddedfool.net/"/>
  <updated>2015-04-08T23:04:48+02:00</updated>
  <id>http://embeddedfool.net/</id>
  <author>
    <name><![CDATA[Kobus Coetzee]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[A More Agile DO-178]]></title>
    <link href="http://embeddedfool.net/blog/2015/04/08/a-more-agile-do-178/"/>
    <updated>2015-04-08T23:02:59+02:00</updated>
    <id>http://embeddedfool.net/blog/2015/04/08/a-more-agile-do-178</id>
    <content type="html"><![CDATA[<p>When looking at software development methodologies, there is in my mind a spectrum that looks something as follows:</p>

<p><img class="center" src="http://embeddedfool.net/images/Development_spectrum.png" width="600" /></p>

<p>So what’s wrong with the extremes of waterfall or agile development, especially concerning safety critical products? Well I think Dilbert may have some advice to share here. Waterfall development typically suffers from the following:</p>

<p><img class="center" src="http://embeddedfool.net/images/dilbert_2001_04_14.png" width="600" /></p>
<center><small>DILBERT © 2001 Scott Adams. Used By permission of UNIVERSAL UCLICK. All rights reserved.</small></center>
<p><br /></p>

<p>With waterfall development, a lot of unnecessary requirements gets specified, because the client is scared that if he doesn’t name every possible use case his product could get used for, he won’t have another chance. The result is bloat, increased costs and increases in the product complexity, not great for safety critical products.</p>

<p>Ok, so agile should be perfect then?</p>

<p><img class="center" src="http://embeddedfool.net/images/dilbert_1997_05_09.gif" width="600" /></p>
<center><small>DILBERT © 1997 Scott Adams. Used By permission of UNIVERSAL UCLICK. All rights reserved.</small></center>
<p><br /></p>

<p>Nope, agile struggles to guarantee that the product is safe. Agile tries to shorten the feedback cycle, “fail fast” or “move fast and break things”. Well when you are developing software for an aircraft, you can’t exactly crash an airplane every time you release and then quickly fix the bug, even if you do it fast…</p>

<p>Ok, so up to now most DO-178 development was done with waterfall methodologies, but what might a more agile DO-178 development process look like?</p>

<p>To answer this question, we have to look at the deliverables required for DO-178 certification, and at what stages of the waterfall development model they are typically produced:</p>

<p><strong>Organisational:</strong><br />
(These can be re-used across multiple projects, if the projects are similar enough off course)</p>

<ul>
  <li>Software configuration management plan (SCM)</li>
  <li>Software quality assurance plan (SQA)</li>
  <li>Software requirements standards (SRS)</li>
  <li>Software design standards (SDS)</li>
  <li>Software code standards (SCS)</li>
  <li>Software verification plan (SVP)</li>
</ul>

<p><strong>At the start of a project - Specification phase:</strong></p>

<ul>
  <li>Plan for software aspects of certification (PSAC)</li>
  <li>Software development plan (SDP)</li>
  <li>Software requirements data (SRD)</li>
  <li>Design description (DD)</li>
</ul>

<p><strong>During development - Implementation phase:</strong></p>

<ul>
  <li>Source code</li>
  <li>Object code</li>
  <li>Software verification Cases and Procedures (SVCP)</li>
  <li>Problem reports</li>
  <li>Software Quality Assurance Records (SQA)</li>
  <li>Software Configuration Management Records (SCMR)</li>
</ul>

<p><strong>At the end of a project - Testing and verification phase:</strong></p>

<ul>
  <li>Software Verification Results (SVR)</li>
  <li>Software Life Cycle Environment Configuration Index (SECI)</li>
  <li>Software Configuration Index (SCI)</li>
  <li>Software Accomplishment Summary (SAS)</li>
</ul>

<p>The problem here is that a lot of the deliverables are generated at the start of a project, before the lessons have been learned. And a lot of the deliverables are generated at the end of a project, not keeping pace with the development of the software, and as such represent a significant source of costs, as these have to be produced and verified manually. </p>

<p>Most of these deliverables also usually takes the form of documentation, with the exception of the source code and object code. DO-178 does not specifically state that the outputs have to be in the form of documentation, and where possible we will try to replace traditionally labour intensive documentation with other artefacts, saving us effort and costs. Off course we must prove that there is no reduction in the reliability of the final product when making these changes.  </p>

<p>The organisational deliverables is not my concern here, as once these have been generated they can be re-used across multiple projects. But let’s see if we can get some of the project specific deliverables be generated and verified continuously and automatically during development using the following:</p>

<h3>Scrum</h3>
<p>During sprint planning and review sessions, we can review and update the Design Description (DD) document detailing the software architecture. At the end of a sprint, the implemented user stories will form the Software Requirements Data (SRD’s). It will look something like this…</p>

<p><img class="center" src="http://embeddedfool.net/images/DO178_scrum.png" width="600" /></p>

<p>During sprint planning we ensure that the user stories i.e. the high level requirements we are planning to implement is consistent with previous implemented requirements.
During sprint review we update the requirements with the implemented user stories, and ensure the created functional tests and unit tests i.e. the low level requirements are consistent with the high level requirements (user stories).</p>

<p>This turns the traditional waterfall model on it’s head. How can you write code and generate the requirements only afterwards? Well a lot of times, you only realise what the true requirements are when you are writing the code, so we only set the requirements in stone once we are sure. We still generate user stories as possible requirements before writing code.</p>

<h3>Continuous integration (CI) and Continuous deployment (CD)</h3>
<p>The CI and CD servers themselves are effectively the Software Life Cycle Environment Configuration Index (SECI), Software Configuration Index (SCI) and parts of the Sofware Configuration Management Records (SCMR) deliverables. For this to be possible, the CI server must have a copy of the version control database when duplicated for certification.   </p>

<p>This means an agile setup might look as follows:</p>

<p><img class="center" src="http://embeddedfool.net/images/agile_setup.png" width="600" /></p>

<p>If all the tests pass, the CI / CD will autogenerate a snapshot of itself (VM’s or some other duplication means) and the version control database to serve as the SECI and SCI. It will also generate reports of the tests run and their results to serve as the SVP and SVR’s, and generate reports that can serve as SCMR items (This is baselines, commit histories etc.). This is off course highly idealistic and represents no small amount of additional work, but the purpose here is to show that these required deliverables of DO-178 is fairly repetative and thus highly automatable. </p>

<h3>Test driven development</h3>
<p>Test driven development can be used to generate the large parts of the Software Verification Cases and Procedures (SVCP’s) and Software Verification Results (SVR’s). High level requirements will be developed and tested with feature driven development, and unit tests will be used to develop and test low level requirements. But not all unit tests are really low level requirements, for instance testing if a function can handle null pointer parameters. As such we will mark which unit tests are indeed low level requirements in the unit testing code itself.  </p>

<p>The relationship between the Continuous integration (CI) server and the Continuous deployment (CD) server is detailed in the popular test pyramid developed by Mike Cohn, where the CI is responsible for making sure the source code compiles at all times, and passes all unit tests, and the CD is responsible for making sure the automated functional tests pass at all times. One would expect to develop a lot more unit tests than functional tests, thereby limiting (but not eliminating) the need for expensive manual testing.</p>

<p><img class="center" src="http://embeddedfool.net/images/testing_pyramid.png" width="600" /></p>

<p>And what will the workflow differences look like between a waterfall and agile DO-178 project? The following represents a very simplified project workflow, but will hopefully give you an idea.</p>

<p><em>Every blue item represents a stage gate, that has to be satisfied before the team can continue on to the next set of items</em></p>

<p><img class="center" src="http://embeddedfool.net/images/agileWaterfallTeamActivities.png" width="600" /></p>

<p>*Sprint review includes a retrospective, code review, functional and unit tests review.</p>

<p>Going back to the DO-178 specification, it lists as an appendix the requirements for the deliverables. The purpose of an agile process would be then to automate the verification of as many of these requirements in order to speed up the certification and re-certification of the product. The difference between how a waterfall or agile work flow satisfies these requirements then looks as follows (DO-178C wording used):</p>

<html>
<style>
#TBody,#Heading
{
text-align:left;
background-color:lightgrey;
border:solid 1px black;
padding:2px;
height:100%
}

#TChange
{
text-align:left;
background-color:red;
border:solid 1px black;
padding:2px;
height:100%
}
</style>
</html>

<p>Table A-1: Software planning process</p>

<table border="1" style="height:100%; width: 100%;">
  <tr>
    <td><div id="Heading"></div></td>
    <td><div id="Heading">Objective</div></td>
    <td><div id="Heading">Output</div></td>
    <td><div id="Heading">Agile strategy</div></td>
  </tr>

  <tr>
    <td><div id="TBody">1</div></td>
    <td><div id="TBody">The activities of the software life cycle processes are defined.</div></td>
    <td rowspan="4"><div id="TBody">Plan for Software Aspects of Certification<br /><br />
                                    Software Development Plan<br /><br />
                                    Software Verification Plan<br /><br />
                                    Software Configuration Management Plan<br /><br />
                                    Software Quality Assurance Plan</div></td> 
    <td><div id="TBody">An agile process is defined.</div></td>
  </tr>

  <tr>
    <td><div id="TBody">2</div></td>
    <td><div id="TBody">The software life cycle(s), including the inter-relationships between the processes, their sequencing, feedback mechanisms, and transition criteria, is defined.</div></td> 
    <td><div id="TBody">An agile process is defined.</div></td>
  </tr>  

  <tr>
    <td><div id="TBody">3</div></td>
    <td><div id="TBody">Software life cycle environment is selected and defined.</div></td> 
    <td><div id="TBody">The CI server is defined as the software lifecycle environment as a final deliverable.</div></td>
  </tr> 

  <tr>
    <td><div id="TBody">4</div></td>
    <td><div id="TBody">Additional considerations are addressed</div></td> 
    <td><div id="TBody">No difference.</div></td>
  </tr> 

  <tr>
    <td><div id="TBody">5</div></td>
    <td><div id="TBody">Software development standards are defined</div></td> 
    <td><div id="TBody">SW Requirements standards<br /><br />
                        SW Design Standards<br /><br />
                        SW Code Standards</div></td>
    <td><div id="TBody">No difference.</div></td>
  </tr>

  <tr>
    <td><div id="TBody">6</div></td>
    <td><div id="TBody">Software plans comply with this document</div></td> 
    <td><div id="TBody">Software Quality Assurance Records<br /><br />
                        Software verification results</div></td>
    <td><div id="TBody">The SVR&#8217;s will now be automatically generated by the unit tests, and the CD server, with a small section still generated manually with manual testing.</div></td>
  </tr>

  <tr>
    <td><div id="TBody">7</div></td>
    <td><div id="TBody">Development and revision of software plans are coordinated.</div></td> 
    <td><div id="TBody">Software Quality Assurance Records<br /><br />
                        Software verification results.</div></td>
    <td><div id="TBody">No difference</div></td>
  </tr>
</table>
<p><br /></p>

<p>Table A-2: Software Development processes</p>

<table border="1" style="height:100px; width: 100%;">
  <tr>
    <td><div id="Heading"></div></td>
    <td><div id="Heading">Objective</div></td>
    <td><div id="Heading">Output</div></td>
    <td><div id="Heading">Agile strategy</div></td>
  </tr>

  <tr>
    <td><div id="TBody">1</div></td>
    <td><div id="TBody">High-level requirements are developed</div></td>
    <td><div id="TBody">Software Requirements Data</div></td> 
    <td><div id="TBody">At the end of each scrum, the implemented user stories will generate the high level requirements section in the SRD.</div></td>
  </tr>

  <tr>
    <td><div id="TBody">2</div></td>
    <td><div id="TBody">Derived high-level requirements are defined and provided to the system processes, including the system safety assessment process.</div></td>
    <td><div id="TBody">Software Requirements Data</div></td> 
    <td><div id="TBody">At the end of each scrum, the implemented derived user stories will generate the high level requirements section in the SRD. There is a problem here, in that the system safety assesment process requires the high level requirements as input, and determines the DO-178 level required, but in an agile process the high level requirements are not defined at the beginning of a project.</div></td>
  </tr>  

  <tr>
    <td><div id="TBody">3</div></td>
    <td><div id="TBody">Software architecture is developed</div></td> 
    <td><div id="TBody">Design description</div></td>    
    <td><div id="TBody">At the beginning of each scrum, the software architecture is reviewed, at the end of each scrum the software architecture document (DD) is updated.</div></td>
  </tr> 

  <tr>
    <td><div id="TBody">4</div></td>
    <td><div id="TBody">Low level requirements are developed</div></td> 
    <td><div id="TBody">Design description</div></td>
    <td><div id="TBody">At the end of each scrum, the implemented unit tests marked as low level requirements will generate the low level requirements section in the DD.</div></td>
  </tr> 

  <tr>
    <td><div id="TBody">5</div></td>
    <td><div id="TBody">Derived low-level requirements are defined and provided to the system processes, including the system safety assessment process.</div></td> 
    <td><div id="TBody">Design description</div></td>
    <td><div id="TBody">At the end of each scrum, the implemented unit tests marked as low level requirements will generate the low level requirements section in the DD.</div></td>
  </tr>

  <tr>
    <td><div id="TBody">6</div></td>
    <td><div id="TBody">Source code is developed</div></td> 
    <td><div id="TBody">Source code</div></td>
    <td><div id="TBody">No difference.</div></td>
  </tr>

  <tr>
    <td><div id="TBody">7</div></td>
    <td><div id="TBody">Executable Object Code and Parameter Data Item Files, if any, are produced and loaded in the target computer.</div></td> 
    <td><div id="TBody">Executable object code</div></td>
    <td><div id="TBody">No difference.</div></td>
  </tr>
</table>
<p><br /></p>

<p>Table A-3: Verification of Outputs of Software Requirements Process</p>

<table border="1" style="height:100px; width: 100%;">
  <tr>
    <td><div id="Heading"></div></td>
    <td><div id="Heading">Objective</div></td>
    <td><div id="Heading">Output</div></td>
    <td><div id="Heading">Agile strategy</div></td>
  </tr>

  <tr>
    <td><div id="TBody">1</div></td>
    <td><div id="TBody">High-level requirements comply with system requirements.</div></td>
    <td><div id="TBody">Software Verification Results</div></td> 
    <td><div id="TBody">At the beginning of each scrum, the suitability of the user stories to be implemented will be evaluated against the system requirements.</div></td>
  </tr>

  <tr>
    <td><div id="TBody">2</div></td>
    <td><div id="TBody">High level requirements are accurate and consistent</div></td>
    <td><div id="TBody">Software Verification Results</div></td> 
    <td><div id="TBody">User stories to be accurate and consistent.</div></td>
  </tr>  

  <tr>
    <td><div id="TBody">3</div></td>
    <td><div id="TBody">High level requirements are compatible with target computer</div></td> 
    <td><div id="TBody">Software Verification Results</div></td>    
    <td><div id="TBody">User stories verified with continuous deployment and functional tests.</div></td>
  </tr> 

  <tr>
    <td><div id="TBody">4</div></td>
    <td><div id="TBody">High level requirements are verifiable</div></td> 
    <td><div id="TBody">Software Verification Results</div></td>
    <td><div id="TBody">User stories verified with continuous deployment and functional tests.</div></td>
  </tr> 

  <tr>
    <td><div id="TBody">5</div></td>
    <td><div id="TBody">High level requirements conform to standards</div></td> 
    <td><div id="TBody">Software Verification Results</div></td>
    <td><div id="TBody">User stories to conform to standards.</div></td>
  </tr>

  <tr>
    <td><div id="TBody">6</div></td>
    <td><div id="TBody">High level requirements are traceable to system requirements</div></td> 
    <td><div id="TBody">Software Verification Results</div></td>
    <td><div id="TBody">No difference.</div></td>
  </tr>

  <tr>
    <td><div id="TBody">7</div></td>
    <td><div id="TBody">Algorithms are accurate</div></td> 
    <td><div id="TBody">Software Verification Results</div></td>
    <td><div id="TBody">No difference.</div></td>
  </tr>
</table>
<p><br /></p>

<p>Table A-4: Verification of Outputs of Software Design Process</p>

<table border="1" style="height:100px; width: 100%;">
  <tr>
    <td><div id="Heading"></div></td>
    <td><div id="Heading">Objective</div></td>
    <td><div id="Heading">Output</div></td>
    <td><div id="Heading">Agile strategy</div></td>
  </tr>

  <tr>
    <td><div id="TBody">1</div></td>
    <td><div id="TBody">Low level requirements comply with high level requirements</div></td>
    <td><div id="TBody">Software Verification Results</div></td> 
    <td><div id="TBody">Newly written unit tests marked as low level requirements will be annotated as to which high level requirement it is traced to and reviewed at every sprint.</div></td>
  </tr>

  <tr>
    <td><div id="TBody">2</div></td>
    <td><div id="TBody">Low level requirements are accurate and consistent</div></td>
    <td><div id="TBody">Software Verification Results</div></td> 
    <td><div id="TBody">Unit tests to be accurate and consistent.</div></td>
  </tr>  

  <tr>
    <td><div id="TBody">3</div></td>
    <td><div id="TBody">Low level requirements are compatible with target computer</div></td> 
    <td><div id="TBody">Software Verification Results</div></td>    
    <td><div id="TBody">Unit tests verified with continuous integration.</div></td>
  </tr> 

  <tr>
    <td><div id="TBody">4</div></td>
    <td><div id="TBody">Low level requirements are verifiable</div></td> 
    <td><div id="TBody">Software Verification Results</div></td>
    <td><div id="TBody">Unit tests verified with continuous integration.</div></td>
  </tr> 

  <tr>
    <td><div id="TBody">5</div></td>
    <td><div id="TBody">Low level requirements conform to standards</div></td> 
    <td><div id="TBody">Software Verification Results</div></td>
    <td><div id="TBody">Unit tests to conform to standards.</div></td>
  </tr>

  <tr>
    <td><div id="TBody">6</div></td>
    <td><div id="TBody">Low level requirements are traceable to High level requirements</div></td> 
    <td><div id="TBody">Software Verification Results</div></td>
    <td><div id="TBody">Unit tests marked as low level requirements will be annotated as to which high level requirement it is traced to.</div></td>
  </tr>

  <tr>
    <td><div id="TBody">7</div></td>
    <td><div id="TBody">Algorithms are accurate</div></td> 
    <td><div id="TBody">Software Verification Results</div></td>
    <td><div id="TBody">Accuracy can be verified with unit tests.</div></td>
  </tr>

  <tr>
    <td><div id="TBody">8</div></td>
    <td><div id="TBody">Software architecture is compatible with high level requirements</div></td> 
    <td><div id="TBody">Software Verification Results</div></td>
    <td><div id="TBody">Software architecture to be reviewed and updated with every sprint.</div></td>
  </tr>

  <tr>
    <td><div id="TBody">9</div></td>
    <td><div id="TBody">Software architecture is consistent</div></td> 
    <td><div id="TBody">Software Verification Results</div></td>
    <td><div id="TBody">Software architecture to be reviewed and updated with every sprint.</div></td>
  </tr>

  <tr>
    <td><div id="TBody">10</div></td>
    <td><div id="TBody">Software architecture is compatible with target computer</div></td> 
    <td><div id="TBody">Software Verification Results</div></td>
    <td><div id="TBody">Software architecture verified with continuous deployment and functional tests.</div></td>
  </tr>

  <tr>
    <td><div id="TBody">11</div></td>
    <td><div id="TBody">Software architecture is verifiable</div></td> 
    <td><div id="TBody">Software Verification Results</div></td>
    <td><div id="TBody">Software architecture verified with continuous deployment and functional tests.</div></td>
  </tr>

  <tr>
    <td><div id="TBody">12</div></td>
    <td><div id="TBody">Software architecture conforms to standards</div></td> 
    <td><div id="TBody">Software Verification Results</div></td>
    <td><div id="TBody">Software architecture to be reviewed and updated with every sprint.</div></td>
  </tr>

  <tr>
    <td><div id="TBody">13</div></td>
    <td><div id="TBody">Software partitioning integrity is confirmed</div></td> 
    <td><div id="TBody">Software Verification Results</div></td>
    <td><div id="TBody">Software partitioning integrity verified with continuous deployment and functional tests.</div></td>
  </tr>
</table>
<p><br /></p>

<p>Table A-5: Verification of Outputs of Software Coding and Integration Process</p>

<table border="1" style="height:100px; width: 100%;">
  <tr>
    <td><div id="Heading"></div></td>
    <td><div id="Heading">Objective</div></td>
    <td><div id="Heading">Output</div></td>
    <td><div id="Heading">Agile strategy</div></td>
  </tr>

  <tr>
    <td><div id="TBody">1</div></td>
    <td><div id="TBody">Source code complies with low level requirements</div></td>
    <td><div id="TBody">Software Verification Results</div></td> 
    <td><div id="TBody">Verified with unit tests.</div></td>
  </tr>

  <tr>
    <td><div id="TBody">2</div></td>
    <td><div id="TBody">Source code complies with software architecture</div></td>
    <td><div id="TBody">Software Verification Results</div></td> 
    <td><div id="TBody">Can be confirmed with sprint code reviews or peer programming.</div></td>
  </tr>  

  <tr>
    <td><div id="TBody">3</div></td>
    <td><div id="TBody">Source code is verifiable</div></td> 
    <td><div id="TBody">Software Verification Results</div></td>    
    <td><div id="TBody">Verified with unit tests and functional tests.</div></td>
  </tr> 

  <tr>
    <td><div id="TBody">4</div></td>
    <td><div id="TBody">Source code conforms to standards</div></td> 
    <td><div id="TBody">Software Verification Results</div></td>
    <td><div id="TBody">Can be confirmed with sprint code reviews or peer programming.</div></td>
  </tr> 

  <tr>
    <td><div id="TBody">5</div></td>
    <td><div id="TBody">Source code is traceable to low level requirements</div></td> 
    <td><div id="TBody">Software Verification Results</div></td>
    <td><div id="TBody">Verified with continuous integration and unit tests.</div></td>
  </tr>

  <tr>
    <td><div id="TBody">6</div></td>
    <td><div id="TBody">Source code is accurate and consistent</div></td> 
    <td><div id="TBody">Software Verification Results</div></td>
    <td><div id="TBody">Can be confirmed with sprint code reviews or peer programming.</div></td>
  </tr>

  <tr>
    <td><div id="TBody">7</div></td>
    <td><div id="TBody">Output of software integration process is complete and correct</div></td> 
    <td><div id="TBody">Software Verification Results</div></td>
    <td><div id="TBody">Software integration process verified with continuous deployment and functional tests.</div></td>
  </tr>

  <tr>
    <td><div id="TBody">8</div></td>
    <td><div id="TBody">Parameter Data Item File is correct and complete</div></td> 
    <td><div id="TBody">Software Verification Cases and Procedures<br /><br />
                        Software Verification Result<br /></div></td>
    <td><div id="TBody">Parameter Data Item File verified with continuous deployment and functional tests.</div></td>
  </tr>

  <tr>
    <td><div id="TBody">9</div></td>
    <td><div id="TBody">Verification of Parameter Data Item File is achieved.</div></td> 
    <td><div id="TBody">Software Verification Results</div></td>
    <td><div id="TBody">Parameter Data Item File verified with continuous deployment and functional tests.</div></td>
  </tr>
</table>
<p><br /></p>

<p>Table A-6: Testing of Outputs of Integration Process</p>

<table border="1" style="height:100px; width: 100%;">
  <tr>
    <td><div id="Heading"></div></td>
    <td><div id="Heading">Objective</div></td>
    <td><div id="Heading">Output</div></td>
    <td><div id="Heading">Agile strategy</div></td>
  </tr>

  <tr>
    <td><div id="TBody">1</div></td>
    <td><div id="TBody">Executable object code complies with high level requirements</div></td>
    <td><div id="TBody">Software Verification Cases and Procedures<br /><br />
                        Software Verification Results</div></td> 
    <td><div id="TBody">User stories verified with continuous deployment and functional tests.</div></td>
  </tr>

  <tr>
    <td><div id="TBody">2</div></td>
    <td><div id="TBody">Executable object code is robust with high level requirements</div></td>
    <td><div id="TBody">Software Verification Cases and Procedures<br /><br />
                        Software Verification Results</div></td> 
    <td><div id="TBody">User stories verified with continuous deployment and functional tests.</div></td>
  </tr>  

  <tr>
    <td><div id="TBody">3</div></td>
    <td><div id="TBody">Executable object code complies with low level requirements</div></td> 
    <td><div id="TBody">Software Verification Cases and Procedures<br /><br />
                        Software Verification Results</div></td>    
    <td><div id="TBody">Verified with continuous integration and unit tests.</div></td>
  </tr> 

  <tr>
    <td><div id="TBody">4</div></td>
    <td><div id="TBody">Executable object code is robust with low level requirements</div></td> 
    <td><div id="TBody">Software Verification Cases and Procedures<br /><br />
                        Software Verification Results</div></td>
    <td><div id="TBody">Verified with continuous integration and unit tests.</div></td>
  </tr> 

  <tr>
    <td><div id="TBody">5</div></td>
    <td><div id="TBody">Executable object code is compatible with target computer</div></td> 
    <td><div id="TBody">Software Verification Cases and Procedures<br /><br />
                        Software Verification Results</div></td>
    <td><div id="TBody">User stories verified with continuous deployment and functional tests.</div></td>
  </tr>
</table>
<p><br /></p>

<p>Table A-7: Verification of Verification Process Results</p>

<table border="1" style="height:100px; width: 100%;">
  <tr>
    <td><div id="Heading"></div></td>
    <td><div id="Heading">Objective</div></td>
    <td><div id="Heading">Output</div></td>
    <td><div id="Heading">Agile strategy</div></td>
  </tr>

  <tr>
    <td><div id="TBody">1</div></td>
    <td><div id="TBody">Test procedures are correct</div></td>
    <td><div id="TBody">Software Verification Cases and Procedures</div></td> 
    <td><div id="TBody">Sprint review of unit tests and functional tests</div></td>
  </tr>

  <tr>
    <td><div id="TBody">2</div></td>
    <td><div id="TBody">Test results are correct and discrepancies explained </div></td>
    <td><div id="TBody">Software Verification Results</div></td> 
    <td><div id="TBody">Sprint review of unit tests and functional tests</div></td>
  </tr>  

  <tr>
    <td><div id="TBody">3</div></td>
    <td><div id="TBody">Test coverage of high level requirements is achieved</div></td> 
    <td><div id="TBody">Software Verification Results</div></td>    
    <td><div id="TBody">Sprint review of unit tests and functional tests</div></td>
  </tr> 

  <tr>
    <td><div id="TBody">4</div></td>
    <td><div id="TBody">Test coverage of low level requirements is achieved</div></td> 
    <td><div id="TBody">Software Verification Results</div></td>
    <td><div id="TBody">Sprint review of unit tests and functional tests</div></td>
  </tr> 

  <tr>
    <td><div id="TBody">5</div></td>
    <td><div id="TBody">Test coverage of software structure (modified condition / decision coverage) is achieved</div></td> 
    <td><div id="TBody">Software Verification Results</div></td>
    <td><div id="TBody">No difference</div></td>
  </tr>

  <tr>
    <td><div id="TBody">6</div></td>
    <td><div id="TBody">Test coverage of software structure (decision coverage) is achieved</div></td> 
    <td><div id="TBody">Software Verification Results</div></td>
    <td><div id="TBody">No difference</div></td>
  </tr>

  <tr>
    <td><div id="TBody">7</div></td>
    <td><div id="TBody">Test coverage of software structure (statement coverage) is achieved</div></td> 
    <td><div id="TBody">Software Verification Results</div></td>
    <td><div id="TBody">No difference</div></td>
  </tr>

  <tr>
    <td><div id="TBody">8</div></td>
    <td><div id="TBody">Test coverage of software structure (data coupling and control coupling) is achieved</div></td> 
    <td><div id="TBody">Software Verification Results</div></td>
    <td><div id="TBody">No difference</div></td>
  </tr>

  <tr>
    <td><div id="TBody">9</div></td>
    <td><div id="TBody">Verification of additional code, that cannot be traced to Source Code, is achieved.</div></td> 
    <td><div id="TBody">Software Verification Results</div></td>
    <td><div id="TBody">No difference</div></td>
  </tr>
</table>
<p><br /></p>

<p>Table A-8: Software Configuration Management Process </p>

<table border="1" style="height:100px; width: 100%;">
  <tr>
    <td><div id="Heading"></div></td>
    <td><div id="Heading">Objective</div></td>
    <td><div id="Heading">Output</div></td>
    <td><div id="Heading">Agile strategy</div></td>
  </tr>

  <tr>
    <td><div id="TBody">1</div></td>
    <td><div id="TBody">Configuration items are identified</div></td>
    <td><div id="TBody">SCM Records</div></td> 
    <td><div id="TBody">No difference</div></td>
  </tr>

  <tr>
    <td><div id="TBody">2</div></td>
    <td><div id="TBody">Baselines and traceability are established</div></td>
    <td><div id="TBody">Software Configuration index <br /><br />
                        SCM Records</div></td> 
    <td><div id="TBody">Baseline generated by cloning the CI / CD, traceability checked not as normal with documented traceability matrixes, but by verifying traceability between annotated unit tests, functional tests and user stories.</div></td>
  </tr>  

  <tr>
    <td><div id="TBody">3</div></td>
    <td><div id="TBody">Problem reporting, change control, change review, and configuration status accounting are established</div></td> 
    <td><div id="TBody">Problem reports<br /><br />
                        SCM Records</div></td>    
    <td><div id="TBody">No difference</div></td>
  </tr> 

  <tr>
    <td><div id="TBody">4</div></td>
    <td><div id="TBody">Archive, retrieval, and release are established</div></td> 
    <td><div id="TBody">SCM Records</div></td>
    <td><div id="TBody">No difference</div></td>
  </tr> 

  <tr>
    <td><div id="TBody">5</div></td>
    <td><div id="TBody">Software load control is established</div></td> 
    <td><div id="TBody">SCM Records</div></td>
    <td><div id="TBody">No difference</div></td>
  </tr>

  <tr>
    <td><div id="TBody">6</div></td>
    <td><div id="TBody">Software life cycle environment control is established</div></td> 
    <td><div id="TBody">Software Life Cycle Environment Configuration Index<br /><br />
                        SCM Records</div></td>
    <td><div id="TBody">No difference</div></td>
  </tr>
</table>
<p><br /></p>

<p>Table A-9: Software Quality Assurance Process </p>

<table border="1" style="height:100px; width: 100%;">
  <tr>
    <td><div id="Heading"></div></td>
    <td><div id="Heading">Objective</div></td>
    <td><div id="Heading">Output</div></td>
    <td><div id="Heading">Agile strategy</div></td>
  </tr>

  <tr>
    <td><div id="TBody">1</div></td>
    <td><div id="TBody">Assurance is obtained that software plans and standards are developed and reviewed for compliance with this document and for consistency.</div></td>
    <td><div id="TBody">Software Quality Assurance Records</div></td> 
    <td><div id="TBody">No difference</div></td>
  </tr>

  <tr>
    <td><div id="TBody">2</div></td>
    <td><div id="TBody">Assurance is obtained that software life cycle processes comply with approved software plans.</div></td>
    <td><div id="TBody">Software Quality Assurance Records</div></td> 
    <td><div id="TBody">No difference</div></td>
  </tr>  

  <tr>
    <td><div id="TBody">3</div></td>
    <td><div id="TBody">Assurance is obtained that software life cycle processes comply with approved software standards.</div></td> 
    <td><div id="TBody">Software Quality Assurance Records</div></td>    
    <td><div id="TBody">No difference</div></td>
  </tr> 

  <tr>
    <td><div id="TBody">4</div></td>
    <td><div id="TBody">Assurance is obtained that transition criteria for the software life cycle processes are satisfied.</div></td> 
    <td><div id="TBody">Software Quality Assurance Records</div></td>    
    <td><div id="TBody">No difference</div></td>
  </tr> 
 
  <tr>
    <td><div id="TBody">5</div></td>
    <td><div id="TBody">Assurance is obtained that software conformity review is conducted.</div></td> 
    <td><div id="TBody">Software Quality Assurance Records</div></td>    
    <td><div id="TBody">No difference</div></td>
  </tr> 
</table>
<p><br /></p>

<p>Table A-10: Certification Liaison Process </p>

<table border="1" style="height:100px; width: 100%;">
  <tr>
    <td><div id="Heading"></div></td>
    <td><div id="Heading">Objective</div></td>
    <td><div id="Heading">Output</div></td>
    <td><div id="Heading">Agile strategy</div></td>
  </tr>

  <tr>
    <td><div id="TBody">1</div></td>
    <td><div id="TBody">Communication and understanding between the applicant and the certification authority is established</div></td>
    <td><div id="TBody">Plan for software aspects of certification</div></td> 
    <td><div id="TBody">No difference</div></td>
  </tr>

  <tr>
    <td><div id="TBody">2</div></td>
    <td><div id="TBody">The means of compliance is proposed and agreement with the Plan for Software Aspects of Certification is obtained</div></td>
    <td><div id="TBody">Plan for software aspects of certification</div></td> 
    <td><div id="TBody">No difference</div></td>
  </tr>  

  <tr>
    <td><div id="TBody">3</div></td>
    <td><div id="TBody">Compliance substantiation is provided</div></td> 
    <td><div id="TBody">Software Accomplishment Summary<br /><br />
                        Software Configuration Index</div></td>    
    <td><div id="TBody">No difference</div></td>
  </tr> 
</table>
<p><br /></p>

<p>So there you have it, a proposal on what a more agile DO-178 development process might look like. I want to make it clear, none of this was developed in a vacuum or my own work, but cherry picked from various sources, which I’ll attribute to as part of the literature study of my thesis. </p>

<p>The question now is, will this pass certification, and can this agile process deliver software of at least the same robustness / quality as a waterfall process delivers. For this question, I will be guiding two three-man student groups to complete the same software project, one group following the waterfall model and another group following the agile model. More on that in the next post (experimental design).</p>

<p>A lot of this post has been quite abstract, not mentioning any specific software solutions to be used during development. The next post will detail the exact solutions the students will use in the form of PSAC and SDP documents, giving more clarity of an agile DO-178 development process. </p>

<p>If I have missed anything or you would like to make a suggestion, kindly do so at the discussion on <a href="https://news.ycombinator.com/item?id=8937549">HN</a> and <a href="http://www.reddit.com/r/programming/comments/2tg71e/do178b_crash_course/">reddit</a>. Comments and suggestions are very welcome.</p>

<p>If you are currently; or in the past have worked on DO-178 projects, it would be appreciated if you would be so kind as to <a href="https://www.surveymonkey.com/s/SV9KX7M">take part in a quick survey</a> about the state of DO-178 development. I will release the results of this survey shortly. Thank you for everyone who has completed the survey already.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[When Is a Team Agile?]]></title>
    <link href="http://embeddedfool.net/blog/2015/01/29/when-is-a-team-agile/"/>
    <updated>2015-01-29T13:30:37+02:00</updated>
    <id>http://embeddedfool.net/blog/2015/01/29/when-is-a-team-agile</id>
    <content type="html"><![CDATA[<h2>Background</h2>
<p>This post serves as part of study on the effectiveness of the DO-178B certification in achieving correctness of implementation and safety guarantees in the presence of incomplete requirements, feature creep and complex technology stacks, also known as your typical software project.</p>

<p>If you are currently; or in the past have worked on DO-178 projects, it would be appreciated if you would be so kind as to <a href="https://www.surveymonkey.com/s/SV9KX7M">take part in a survey</a> about the state of DO-178 development.</p>

<p>One of the challenges in defining a more agile DO-178 process, is proving that the process is actually agile. Proving it conforms to DO-178 is easy, there is an entire specification written for that, but agile…hmmm.  </p>

<h2>So what is agile?</h2>
<p>What a question…the software development world is a buzz with agile this and agile that, but ask any practitioner of agile software development this question, and you’ll invariably get a different answer from <a href="http://www.cio.com/article/2385322/agile-development/why-agile-isn-t-working--bringing-common-sense-to-agile-principles.html">each</a> and <a href="http://www.allaboutagile.com/category/10-key-principles-of-agile/">every</a> one of <a href="http://pragdave.me/blog/2014/03/04/time-to-kill-agile/">them.</a></p>

<p>So to ask the question, lets first frame what I mean with agile. In my mind, agile can be seen to exist on three tiers, let’s call it the agile pyramid if you will. </p>

<p><img class="center" src="http://embeddedfool.net/images/agile_pyramid.png" width="600" /></p>

<h4>Tier 1- Philosophy</h4>
<p>First tier is the <a href="http://www.agilemanifesto.org/">agile manifesto</a>, where it all began off course. The manifesto states:</p>

<ul>
  <li><em>Individuals and interactions over processes and tools</em></li>
  <li><em>Working software over comprehensive documentation</em></li>
  <li><em>Customer collaboration over contract negotiation</em></li>
  <li><em>Responding to change over following a plan</em> </li>
</ul>

<p>The agile manifesto also talks about twelve principles of agile, but I think the above four statements captures the intention well enough.</p>

<p>Now the manifesto sounds great and all, but it doesn’t give you much of an example to work with on how to run an agile project. Fortunately shortly after the manifesto Kent Beck lead a <a href="http://en.wikipedia.org/wiki/Chrysler_Comprehensive_Compensation_System">software project</a> that has been studied quite a bit, and gave rise to <a href="http://en.wikipedia.org/wiki/Extreme_programming">Extreme Programming (XP)</a>. But extreme programming was a little bit too extreme for some, and besides, project managers still didn’t have much of a clue about how this agile thing works exactly anyway, which leads us to our next tier in the pyramid.</p>

<h4>Tier 2- Project management</h4>

<p>In order to formalize what agile software development is exactly, legions of consultants sprang up to <a href="http://www.thoughtworks.com/talks/the-death-of-agile">teach these projects managers and their programmers</a>. What came forth was the leading agile development methodology, Scrum, but also Kanban. </p>

<p><img class="center" src="http://embeddedfool.net/images/scrum.png" width="600" /></p>

<p>Ok so scrum is a daily ritual of scrum masters, stand up meetings, user stories, time limits and velocity tracking. Oh and Kanban boards.</p>

<p><img class="center" src="http://embeddedfool.net/images/kanban.png" width="600" />  </p>

<p>So what is the difference between Scrum and Kanban? Well, not much, except Scrum could be described as the anal retentive cousin of Kanban. For where scrum has roles, time limits, velocity tracking, daily meetings, scrum masters etc, Kanban has none, just a board and a team.  (Ok I might just have started a religious war, don’t take this stuff too seriously).</p>

<h4>Tier 3- Best practices</h4>

<p>So Scrum and Kanban relies on certain agile best practices to really succeed, and if you really get down to it, this can become a very long list. I’ve listed the most important ones for my purposes (agile DO-178), but there are many more:</p>

<ul>
  <li><a href="http://en.wikipedia.org/wiki/Continuous_integration">Continuous integration</a></li>
  <li><a href="http://en.wikipedia.org/wiki/Continuous_delivery">Continuous deployment</a></li>
  <li><a href="http://en.wikipedia.org/wiki/Pair_programming">Pair programming</a></li>
  <li>Regular code refactoring</li>
  <li><a href="http://en.wikipedia.org/wiki/Velocity_%28software_development%29">Velocity tracking</a></li>
  <li><a href="http://en.wikipedia.org/wiki/Feature-driven_development">Feature driven development</a></li>
  <li><a href="http://en.wikipedia.org/wiki/Test-driven_development">Test driven development</a></li>
  <li><a href="http://en.wikipedia.org/wiki/Behavior-driven_development">Behaviour driven development</a></li>
</ul>

<p>Ok so back to my initial question, at what point can it be said a team is agile? Is it only necessary that the spirit of agile is followed (agile manifesto), or only when the entire pyramid is in effect?</p>

<p>Please join the discussion at <a href="https://news.ycombinator.com/item?id=8993760">HN</a> and <a href="https://www.reddit.com/r/programming/comments/2uoo15/when_is_a_team_agile/">reddit</a>. Comments are very welcome.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[DO-178B Crash Course]]></title>
    <link href="http://embeddedfool.net/blog/2015/01/23/do-178b-crash-course/"/>
    <updated>2015-01-23T11:37:00+02:00</updated>
    <id>http://embeddedfool.net/blog/2015/01/23/do-178b-crash-course</id>
    <content type="html"><![CDATA[<h2>Background</h2>
<p>This post serves part of a three part introductory primer for 3rd year computer science students as to the typical working of a software project seeking DO-178B certification. The other parts can be found here:<br />
<a href="">Agile crash course (TBC)</a><br />
<a href="">A more agile DO-178 (TBC)</a></p>

<p>The students will form part of a study on the effectiveness of the DO-178B certification in achieving correctness of implementation and safety guarantees in the presence of incomplete requirements, feature creep and complex technology stacks, also known as your typical software project.</p>

<p>If you are currently; or in the past have worked on DO-178 projects, it would be appreciated if you would be so kind as to <a href="https://www.surveymonkey.com/s/SV9KX7M">take part in a survey</a> about the state of DO-178 development.  </p>

<h2>What is DO-178?</h2>
<p>First let’s start with what is DO-178? DO-178 is an international standard for the assurance of the safety of avionics software. It is published by <a href="http://www.rtca.org/">RTCA, Incorporated</a>, and the latest revision of the standard is known as <a href="http://en.wikipedia.org/wiki/DO-178C">DO-178C</a>, although <a href="http://en.wikipedia.org/wiki/DO-178B">DO-178B</a> is still widely implemented and is the subject of this post.</p>

<p>Although DO-178 is concerned with the software of airborne systems and equipment, various other industries concerned about safety critical software have adopted the standard to certify its software. DO-178 ties closely with <a href="http://en.wikipedia.org/wiki/DO-254">DO-254</a> which is concerned with development of airborne electronic hardware, and <a href="http://en.wikipedia.org/wiki/ARP4754">SAE ARP4753</a> which is concerned with system level considerations of airborne equipment. There also exists other independant standards with much the same goals as DO-178, namely the IEC 61508 based standards; <a href="http://en.wikipedia.org/wiki/IEC_60601">IEC60601-1</a> for medical devices; <a href="http://en.wikipedia.org/wiki/ISO_26262">ISO26262</a> for automotive electronics and <a href="http://webstore.iec.ch/Webstore/webstore.nsf/ArtNum_PK/26619!opendocument&amp;preview=1">IEC 60880-2</a> for the nuclear energy industry.</p>

<p>This post is not concerned with the actual certification aspects of DO-178B, but with the process DO-178B enforces on software development to ensure the safety and correctness guarantees it attempts to achieve. For a better overview of the actual certification process, especially as it relates to FAA certification, look <a href="http://www.sandroid.org/birdsproject/4dummies.html">here</a>. Also another excellent overview of DO-178B can be found in <a href="http://www.amazon.com/The-Avionics-Handbook-Electrical-Engineering/dp/084938348X">The Avionics Handbook</a> chapter 27.   </p>

<h2>Criticality level</h2>
<p>DO-178B specifies 5 levels of criticality to which a system can be developed. The amount of effort involved in satisfying the DO-178B certification depends on the criticality level of your software and as such is the first consideration you should have when starting your product development cycle. The criticality level is determined from the possible consequences that anomalous software would have on the aircraft.</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\begin{array}{c|lcr}
\text{Criticality} & \text{Failure condition} & \text{Software definition} & \text{Objectives}\\
\hline
\text{Level A} & \text{Catastrophic} & \text{Prevents continued safe flight} & 66 \\
\\
\text{Level B} & \text{Hazardous} & \text{Large reduction in safety margin} & 65 \\
 			   &				  & \text{Physical distress or higher workload} \\ 
 			   &				  & \text{Adverse effects on occupants} \\
\\
\text{Level C} & \text{Major} & \text{Reduction in safety margin} & 57 \\
\\
\text{Level D} & \text{Minor} & \text{Would not significantly reduce safety} & 28\\
\\
\text{Level E} & \text{No effect} & \text{Does not affect operational capability} & 0
\end{array}
 %]]&gt;</script>

<p>There is very little data on the amount of additional effort that each level requires, with some sources claiming only an <a href="http://www.highrely.com/whitepapers.php">increase of 75% to 150%</a>, and others claiming a <a href="http://www.cs.york.ac.uk/hise/safety-critical-archive/2009/0738.html">1000% increase in costs</a>. It depends on various factors off course, such as the experience of the team, complexity of the software, software development lifecycle etc. But a relative measure of the increase in workload can be gauged from the increasing objectives to be met for each criticality level.   </p>

<h2>List of deliverables to be completed</h2>
<p>Since DO-178B is a software quality assurance standard, not a software development standard, it does not impose any restrictions or considerations on how software is to be developed.</p>

<p>It does however require the following list of deliverables, with the requirements for each depending on the criticality level chosen (click on each deliverable for a description):  </p>

<html>
<head>
<script src="http://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
<script>
$(document).ready(function(){
  $("#levelA").click(function(){
    $("#PSAC").fadeTo("slow", 1.00);
	$("#PSAC_indep").text("-");
    $("#PSAC_obj").text("6");
	$("#SDP").fadeTo("slow", 1.00);
    $("#SDP_indep").text("-");
    $("#SDP_obj").text("4");
	$("#SVP").fadeTo("slow", 1.00);
	$("#SVP_indep").text("-");
    $("#SVP_obj").text("4");
	$("#SCMP").fadeTo("slow", 1.00);
	$("#SCMP_indep").text("-");
    $("#SCMP_obj").text("4");
	$("#SQAP").fadeTo("slow", 1.00);
	$("#SQAP_indep").text("-");
    $("#SQAP_obj").text("4");
	$("#SRS").fadeTo("slow", 1.00);
	$("#SRS_indep").text("-");
    $("#SRS_obj").text("1");
	$("#SDS").fadeTo("slow", 1.00);
	$("#SDS_indep").text("-");
    $("#SDS_obj").text("1");
	$("#SCS").fadeTo("slow", 1.00);
	$("#SCS_indep").text("-");
    $("#SCS_obj").text("1");
	$("#SRD").fadeTo("slow", 1.00);
	$("#SRD_indep").text("-");
    $("#SRD_obj").text("2");
	$("#SDD").fadeTo("slow", 1.00);
	$("#SDD_indep").text("-");
    $("#SDD_obj").text("3");
	$("#Source").fadeTo("slow", 1.00);
	$("#Source_indep").text("-");
    $("#Source_obj").text("1");
	$("#Executable").fadeTo("slow", 1.00);
	$("#Executable_indep").text("-");
    $("#Executable_obj").text("1");
	$("#SVCP").fadeTo("slow", 1.00);
	$("#SVCP_indep").text("3");
    $("#SVCP_obj").text("3");
	$("#SVR").fadeTo("slow", 1.00);
	$("#SVR_indep").text("21");
    $("#SVR_obj").text("23");
	$("#SECI").fadeTo("slow", 1.00);
	$("#SECI_indep").text("-");
    $("#SECI_obj").text("1");
	$("#SCI").fadeTo("slow", 1.00);
	$("#SCI_indep").text("-");
    $("#SCI_obj").text("2");
	$("#Problems").fadeTo("slow", 1.00);
	$("#Problems_indep").text("-");
    $("#Problems_obj").text("1");
	$("#Configs").fadeTo("slow", 1.00);
	$("#Configs_indep").text("-");
    $("#Configs_obj").text("6");
	$("#QA").fadeTo("slow", 1.00);
	$("#QA_indep").text("3");
    $("#QA_obj").text("2");
	$("#SAS").fadeTo("slow", 1.00);
	$("#SAS_indep").text("-");
    $("#SAS_obj").text("1");
  });
  $("#levelB").click(function(){
    $("#PSAC").fadeTo("slow", 1.00);
	$("#PSAC_indep").text("-");
    $("#PSAC_obj").text("6");
	$("#SDP").fadeTo("slow", 1.00);
    $("#SDP_indep").text("-");
    $("#SDP_obj").text("4");
	$("#SVP").fadeTo("slow", 1.00);
	$("#SVP_indep").text("-");
    $("#SVP_obj").text("4");
	$("#SCMP").fadeTo("slow", 1.00);
	$("#SCMP_indep").text("-");
    $("#SCMP_obj").text("4");
	$("#SQAP").fadeTo("slow", 1.00);
	$("#SQAP_indep").text("-");
    $("#SQAP_obj").text("4");
	$("#SRS").fadeTo("slow", 1.00);
	$("#SRS_indep").text("-");
    $("#SRS_obj").text("1");
	$("#SDS").fadeTo("slow", 1.00);
	$("#SDS_indep").text("-");
    $("#SDS_obj").text("1");
	$("#SCS").fadeTo("slow", 1.00);
	$("#SCS_indep").text("-");
    $("#SCS_obj").text("1");
	$("#SRD").fadeTo("slow", 1.00);
	$("#SRD_indep").text("-");
    $("#SRD_obj").text("2");
	$("#SDD").fadeTo("slow", 1.00);
	$("#SDD_indep").text("-");
    $("#SDD_obj").text("3");
	$("#Source").fadeTo("slow", 1.00);
	$("#Source_indep").text("-");
    $("#Source_obj").text("1");
	$("#Executable").fadeTo("slow", 1.00);
	$("#Executable_indep").text("-");
    $("#Executable_obj").text("1");
	$("#SVCP").fadeTo("slow", 1.00);
	$("#SVCP_indep").text("1");
    $("#SVCP_obj").text("5");
	$("#SVR").fadeTo("slow", 1.00);
	$("#SVR_indep").text("11");
    $("#SVR_obj").text("32");
	$("#SECI").fadeTo("slow", 1.00);
	$("#SECI_indep").text("-");
    $("#SECI_obj").text("1");
	$("#SCI").fadeTo("slow", 1.00);
	$("#SCI_indep").text("-");
    $("#SCI_obj").text("2");
	$("#Problems").fadeTo("slow", 1.00);
	$("#Problems_indep").text("-");
    $("#Problems_obj").text("1");
	$("#Configs").fadeTo("slow", 1.00);
	$("#Configs_indep").text("-");
    $("#Configs_obj").text("6");
	$("#QA").fadeTo("slow", 1.00);
	$("#QA_indep").text("3");
    $("#QA_obj").text("2");
	$("#SAS").fadeTo("slow", 1.00);
	$("#SAS_indep").text("-");
    $("#SAS_obj").text("1");
  });
  $("#levelC").click(function(){
    $("#PSAC").fadeTo("slow", 1.00);
	$("#PSAC_indep").text("-");
    $("#PSAC_obj").text("6");
	$("#SDP").fadeTo("slow", 1.00);
    $("#SDP_indep").text("-");
    $("#SDP_obj").text("4");
	$("#SVP").fadeTo("slow", 1.00);
	$("#SVP_indep").text("-");
    $("#SVP_obj").text("4");
	$("#SCMP").fadeTo("slow", 1.00);
	$("#SCMP_indep").text("-");
    $("#SCMP_obj").text("4");
	$("#SQAP").fadeTo("slow", 1.00);
	$("#SQAP_indep").text("-");
    $("#SQAP_obj").text("4");
	$("#SRS").fadeTo("slow", 1.00);
	$("#SRS_indep").text("-");
    $("#SRS_obj").text("1");
	$("#SDS").fadeTo("slow", 1.00);
	$("#SDS_indep").text("-");
    $("#SDS_obj").text("1");
	$("#SCS").fadeTo("slow", 1.00);
	$("#SCS_indep").text("-");
    $("#SCS_obj").text("1");
	$("#SRD").fadeTo("slow", 1.00);
	$("#SRD_indep").text("-");
    $("#SRD_obj").text("2");
	$("#SDD").fadeTo("slow", 1.00);
	$("#SDD_indep").text("-");
    $("#SDD_obj").text("3");
	$("#Source").fadeTo("slow", 1.00);
	$("#Source_indep").text("-");
    $("#Source_obj").text("1");
	$("#Executable").fadeTo("slow", 1.00);
	$("#Executable_indep").text("-");
    $("#Executable_obj").text("1");
	$("#SVCP").fadeTo("slow", 1.00);
	$("#SVCP_indep").text("-");
    $("#SVCP_obj").text("6");
	$("#SVR").fadeTo("slow", 1.00);
	$("#SVR_indep").text("-");
    $("#SVR_obj").text("33");
	$("#SECI").fadeTo("slow", 1.00);
	$("#SECI_indep").text("-");
    $("#SECI_obj").text("1");
	$("#SCI").fadeTo("slow", 1.00);
	$("#SCI_indep").text("-");
    $("#SCI_obj").text("2");
	$("#Problems").fadeTo("slow", 1.00);
	$("#Problems_indep").text("-");
    $("#Problems_obj").text("1");
	$("#Configs").fadeTo("slow", 1.00);
	$("#Configs_indep").text("-");
    $("#Configs_obj").text("6");
	$("#QA").fadeTo("slow", 1.00);
	$("#QA_indep").text("2");
    $("#QA_obj").text("2");
	$("#SAS").fadeTo("slow", 1.00);
	$("#SAS_indep").text("-");
    $("#SAS_obj").text("1");
  });
  $("#levelD").click(function(){
    $("#PSAC").fadeTo("slow", 1.00);
	$("#PSAC_indep").text("-");
    $("#PSAC_obj").text("4");
	$("#SDP").fadeTo("slow", 1.00);
    $("#SDP_indep").text("-");
    $("#SDP_obj").text("2");
	$("#SVP").fadeTo("slow", 1.00);
	$("#SVP_indep").text("-");
    $("#SVP_obj").text("2");
	$("#SCMP").fadeTo("slow", 1.00);
	$("#SCMP_indep").text("-");
    $("#SCMP_obj").text("2");
	$("#SQAP").fadeTo("slow", 1.00);
	$("#SQAP_indep").text("-");
    $("#SQAP_obj").text("2");
	$("#SRS").fadeTo("slow", 0.15);
	$("#SRS_indep").text("-");
    $("#SRS_obj").text("-");
	$("#SDS").fadeTo("slow", 0.15);
	$("#SDS_indep").text("-");
    $("#SDS_obj").text("-");
	$("#SCS").fadeTo("slow", 0.15);
	$("#SCS_indep").text("-");
    $("#SCS_obj").text("-");
	$("#SRD").fadeTo("slow", 1.00);
	$("#SRD_indep").text("-");
    $("#SRD_obj").text("2");
	$("#SDD").fadeTo("slow", 1.00);
	$("#SDD_indep").text("-");
    $("#SDD_obj").text("3");
	$("#Source").fadeTo("slow", 1.00);
	$("#Source_indep").text("-");
    $("#Source_obj").text("1");
	$("#Executable").fadeTo("slow", 1.00);
	$("#Executable_indep").text("-");
    $("#Executable_obj").text("1");
	$("#SVCP").fadeTo("slow", 1.00);
	$("#SVCP_indep").text("-");
    $("#SVCP_obj").text("3");
	$("#SVR").fadeTo("slow", 1.00);
	$("#SVR_indep").text("-");
    $("#SVR_obj").text("8");
	$("#SECI").fadeTo("slow", 1.00);
	$("#SECI_indep").text("-");
    $("#SECI_obj").text("1");
	$("#SCI").fadeTo("slow", 1.00);
	$("#SCI_indep").text("-");
    $("#SCI_obj").text("2");
	$("#Problems").fadeTo("slow", 1.00);
	$("#Problems_indep").text("-");
    $("#Problems_obj").text("1");
	$("#Configs").fadeTo("slow", 1.00);
	$("#Configs_indep").text("-");
    $("#Configs_obj").text("6");
	$("#QA").fadeTo("slow", 1.00);
	$("#QA_indep").text("2");
    $("#QA_obj").text("-");
	$("#SAS").fadeTo("slow", 1.00);
	$("#SAS_indep").text("-");
    $("#SAS_obj").text("1");
  });
  $("#levelE").click(function(){
    $("#PSAC").fadeTo("slow", 1);
	$("#PSAC_indep").text("-");
    $("#PSAC_obj").text("-");
	$("#SDP").fadeTo("slow", 0.15);
    $("#SDP_indep").text("-");
    $("#SDP_obj").text("-");
	$("#SVP").fadeTo("slow", 0.15);
	$("#SVP_indep").text("-");
    $("#SVP_obj").text("-");
	$("#SCMP").fadeTo("slow", 0.15);
	$("#SCMP_indep").text("-");
    $("#SCMP_obj").text("-");
	$("#SQAP").fadeTo("slow", 0.15);
	$("#SQAP_indep").text("-");
    $("#SQAP_obj").text("-");
	$("#SRS").fadeTo("slow", 0.15);
	$("#SRS_indep").text("-");
    $("#SRS_obj").text("-");
	$("#SDS").fadeTo("slow", 0.15);
	$("#SDS_indep").text("-");
    $("#SDS_obj").text("-");
	$("#SCS").fadeTo("slow", 0.15);
	$("#SCS_indep").text("-");
    $("#SCS_obj").text("-");
	$("#SRD").fadeTo("slow", 0.15);
	$("#SRD_indep").text("-");
    $("#SRD_obj").text("-");
	$("#SDD").fadeTo("slow", 0.15);
	$("#SDD_indep").text("-");
    $("#SDD_obj").text("-");
	$("#Source").fadeTo("slow", 0.15);
	$("#Source_indep").text("-");
    $("#Source_obj").text("-");
	$("#Executable").fadeTo("slow", 0.15);
	$("#Executable_indep").text("-");
    $("#Executable_obj").text("-");
	$("#SVCP").fadeTo("slow", 0.15);
	$("#SVCP_indep").text("-");
    $("#SVCP_obj").text("-");
	$("#SVR").fadeTo("slow", 0.15);
	$("#SVR_indep").text("-");
    $("#SVR_obj").text("-");
	$("#SECI").fadeTo("slow", 0.15);
	$("#SECI_indep").text("-");
    $("#SECI_obj").text("-");
	$("#SCI").fadeTo("slow", 0.15);
	$("#SCI_indep").text("-");
    $("#SCI_obj").text("-");
	$("#Problems").fadeTo("slow", 0.15);
	$("#Problems_indep").text("-");
    $("#Problems_obj").text("-");
	$("#Configs").fadeTo("slow", 0.15);
	$("#Configs_indep").text("-");
    $("#Configs_obj").text("-");
	$("#QA").fadeTo("slow", 0.15);
	$("#QA_indep").text("-");
    $("#QA_obj").text("-");
	$("#SAS").fadeTo("slow", 0.15);
	$("#SAS_indep").text("-");
    $("#SAS_obj").text("-");
  });

  $("#PSAC").click(function(){
    $("#PSAC_flip").slideToggle("slow");
	$("#SDP_flip").slideUp("slow");
	$("#SVP_flip").slideUp("slow");
	$("#SCMP_flip").slideUp("slow");
	$("#SQAP_flip").slideUp("slow");
	$("#SRS_flip").slideUp("slow");
	$("#SDS_flip").slideUp("slow");
	$("#SCS_flip").slideUp("slow");
	$("#SRD_flip").slideUp("slow");
	$("#SDD_flip").slideUp("slow");
	$("#Source_flip").slideUp("slow");
	$("#Executable_flip").slideUp("slow");
	$("#SVCP_flip").slideUp("slow");
	$("#SVR_flip").slideUp("slow");
	$("#SECI_flip").slideUp("slow");
	$("#SCI_flip").slideUp("slow");
	$("#Problems_flip").slideUp("slow");
	$("#Configs_flip").slideUp("slow");
	$("#QA_flip").slideUp("slow");
	$("#SAS_flip").slideUp("slow");
  });
  $("#SDP").click(function(){
    $("#PSAC_flip").slideUp("slow");
	$("#SDP_flip").slideToggle("slow");
	$("#SVP_flip").slideUp("slow");
	$("#SCMP_flip").slideUp("slow");
	$("#SQAP_flip").slideUp("slow");
	$("#SRS_flip").slideUp("slow");
	$("#SDS_flip").slideUp("slow");
	$("#SCS_flip").slideUp("slow");
	$("#SRD_flip").slideUp("slow");
	$("#SDD_flip").slideUp("slow");
	$("#Source_flip").slideUp("slow");
	$("#Executable_flip").slideUp("slow");
	$("#SVCP_flip").slideUp("slow");
	$("#SVR_flip").slideUp("slow");
	$("#SECI_flip").slideUp("slow");
	$("#SCI_flip").slideUp("slow");
	$("#Problems_flip").slideUp("slow");
	$("#Configs_flip").slideUp("slow");
	$("#QA_flip").slideUp("slow");
	$("#SAS_flip").slideUp("slow");
  });	
  $("#SVP").click(function(){
    $("#PSAC_flip").slideUp("slow");
	$("#SDP_flip").slideUp("slow");
	$("#SVP_flip").slideToggle("slow");
	$("#SCMP_flip").slideUp("slow");
	$("#SQAP_flip").slideUp("slow");
	$("#SRS_flip").slideUp("slow");
	$("#SDS_flip").slideUp("slow");
	$("#SCS_flip").slideUp("slow");
	$("#SRD_flip").slideUp("slow");
	$("#SDD_flip").slideUp("slow");
	$("#Source_flip").slideUp("slow");
	$("#Executable_flip").slideUp("slow");
	$("#SVCP_flip").slideUp("slow");
	$("#SVR_flip").slideUp("slow");
	$("#SECI_flip").slideUp("slow");
	$("#SCI_flip").slideUp("slow");
	$("#Problems_flip").slideUp("slow");
	$("#Configs_flip").slideUp("slow");
	$("#QA_flip").slideUp("slow");
	$("#SAS_flip").slideUp("slow");
  });
  $("#SCMP").click(function(){
    $("#PSAC_flip").slideUp("slow");
	$("#SDP_flip").slideUp("slow");
	$("#SVP_flip").slideUp("slow");
	$("#SCMP_flip").slideToggle("slow");
	$("#SQAP_flip").slideUp("slow");
	$("#SRS_flip").slideUp("slow");
	$("#SDS_flip").slideUp("slow");
	$("#SCS_flip").slideUp("slow");
	$("#SRD_flip").slideUp("slow");
	$("#SDD_flip").slideUp("slow");
	$("#Source_flip").slideUp("slow");
	$("#Executable_flip").slideUp("slow");
	$("#SVCP_flip").slideUp("slow");
	$("#SVR_flip").slideUp("slow");
	$("#SECI_flip").slideUp("slow");
	$("#SCI_flip").slideUp("slow");
	$("#Problems_flip").slideUp("slow");
	$("#Configs_flip").slideUp("slow");
	$("#QA_flip").slideUp("slow");
	$("#SAS_flip").slideUp("slow");
  });
  $("#SQAP").click(function(){
    $("#PSAC_flip").slideUp("slow");
	$("#SDP_flip").slideUp("slow");
	$("#SVP_flip").slideUp("slow");
	$("#SCMP_flip").slideUp("slow");
	$("#SQAP_flip").slideToggle("slow");
	$("#SRS_flip").slideUp("slow");
	$("#SDS_flip").slideUp("slow");
	$("#SCS_flip").slideUp("slow");
	$("#SRD_flip").slideUp("slow");
	$("#SDD_flip").slideUp("slow");
	$("#Source_flip").slideUp("slow");
	$("#Executable_flip").slideUp("slow");
	$("#SVCP_flip").slideUp("slow");
	$("#SVR_flip").slideUp("slow");
	$("#SECI_flip").slideUp("slow");
	$("#SCI_flip").slideUp("slow");
	$("#Problems_flip").slideUp("slow");
	$("#Configs_flip").slideUp("slow");
	$("#QA_flip").slideUp("slow");
	$("#SAS_flip").slideUp("slow");
  });
  $("#SRS").click(function(){
    $("#PSAC_flip").slideUp("slow");
	$("#SDP_flip").slideUp("slow");
	$("#SVP_flip").slideUp("slow");
	$("#SCMP_flip").slideUp("slow");
	$("#SQAP_flip").slideUp("slow");
	$("#SRS_flip").slideToggle("slow");
	$("#SDS_flip").slideUp("slow");
	$("#SCS_flip").slideUp("slow");
	$("#SRD_flip").slideUp("slow");
	$("#SDD_flip").slideUp("slow");
	$("#Source_flip").slideUp("slow");
	$("#Executable_flip").slideUp("slow");
	$("#SVCP_flip").slideUp("slow");
	$("#SVR_flip").slideUp("slow");
	$("#SECI_flip").slideUp("slow");
	$("#SCI_flip").slideUp("slow");
	$("#Problems_flip").slideUp("slow");
	$("#Configs_flip").slideUp("slow");
	$("#QA_flip").slideUp("slow");
	$("#SAS_flip").slideUp("slow");
  });
  $("#SDS").click(function(){
    $("#PSAC_flip").slideUp("slow");
	$("#SDP_flip").slideUp("slow");
	$("#SVP_flip").slideUp("slow");
	$("#SCMP_flip").slideUp("slow");
	$("#SQAP_flip").slideUp("slow");
	$("#SRS_flip").slideUp("slow");
	$("#SDS_flip").slideToggle("slow");
	$("#SCS_flip").slideUp("slow");
	$("#SRD_flip").slideUp("slow");
	$("#SDD_flip").slideUp("slow");
	$("#Source_flip").slideUp("slow");
	$("#Executable_flip").slideUp("slow");
	$("#SVCP_flip").slideUp("slow");
	$("#SVR_flip").slideUp("slow");
	$("#SECI_flip").slideUp("slow");
	$("#SCI_flip").slideUp("slow");
	$("#Problems_flip").slideUp("slow");
	$("#Configs_flip").slideUp("slow");
	$("#QA_flip").slideUp("slow");
	$("#SAS_flip").slideUp("slow");
  });
  $("#SCS").click(function(){
    $("#PSAC_flip").slideUp("slow");
	$("#SDP_flip").slideUp("slow");
	$("#SVP_flip").slideUp("slow");
	$("#SCMP_flip").slideUp("slow");
	$("#SQAP_flip").slideUp("slow");
	$("#SRS_flip").slideUp("slow");
	$("#SDS_flip").slideUp("slow");
	$("#SCS_flip").slideToggle("slow");
	$("#SRD_flip").slideUp("slow");
	$("#SDD_flip").slideUp("slow");
	$("#Source_flip").slideUp("slow");
	$("#Executable_flip").slideUp("slow");
	$("#SVCP_flip").slideUp("slow");
	$("#SVR_flip").slideUp("slow");
	$("#SECI_flip").slideUp("slow");
	$("#SCI_flip").slideUp("slow");
	$("#Problems_flip").slideUp("slow");
	$("#Configs_flip").slideUp("slow");
	$("#QA_flip").slideUp("slow");
	$("#SAS_flip").slideUp("slow");
  });
  $("#SRD").click(function(){
    $("#PSAC_flip").slideUp("slow");
	$("#SDP_flip").slideUp("slow");
	$("#SVP_flip").slideUp("slow");
	$("#SCMP_flip").slideUp("slow");
	$("#SQAP_flip").slideUp("slow");
	$("#SRS_flip").slideUp("slow");
	$("#SDS_flip").slideUp("slow");
	$("#SCS_flip").slideUp("slow");
	$("#SRD_flip").slideToggle("slow");
	$("#SDD_flip").slideUp("slow");
	$("#Source_flip").slideUp("slow");
	$("#Executable_flip").slideUp("slow");
	$("#SVCP_flip").slideUp("slow");
	$("#SVR_flip").slideUp("slow");
	$("#SECI_flip").slideUp("slow");
	$("#SCI_flip").slideUp("slow");
	$("#Problems_flip").slideUp("slow");
	$("#Configs_flip").slideUp("slow");
	$("#QA_flip").slideUp("slow");
	$("#SAS_flip").slideUp("slow");
  });
  $("#SDD").click(function(){
    $("#PSAC_flip").slideUp("slow");
	$("#SDP_flip").slideUp("slow");
	$("#SVP_flip").slideUp("slow");
	$("#SCMP_flip").slideUp("slow");
	$("#SQAP_flip").slideUp("slow");
	$("#SRS_flip").slideUp("slow");
	$("#SDS_flip").slideUp("slow");
	$("#SCS_flip").slideUp("slow");
	$("#SRD_flip").slideUp("slow");
	$("#SDD_flip").slideToggle("slow");
	$("#Source_flip").slideUp("slow");
	$("#Executable_flip").slideUp("slow");
	$("#SVCP_flip").slideUp("slow");
	$("#SVR_flip").slideUp("slow");
	$("#SECI_flip").slideUp("slow");
	$("#SCI_flip").slideUp("slow");
	$("#Problems_flip").slideUp("slow");
	$("#Configs_flip").slideUp("slow");
	$("#QA_flip").slideUp("slow");
	$("#SAS_flip").slideUp("slow");
  });
  $("#Source").click(function(){
    $("#PSAC_flip").slideUp("slow");
	$("#SDP_flip").slideUp("slow");
	$("#SVP_flip").slideUp("slow");
	$("#SCMP_flip").slideUp("slow");
	$("#SQAP_flip").slideUp("slow");
	$("#SRS_flip").slideUp("slow");
	$("#SDS_flip").slideUp("slow");
	$("#SCS_flip").slideUp("slow");
	$("#SRD_flip").slideUp("slow");
	$("#SDD_flip").slideUp("slow");
	$("#Source_flip").slideToggle("slow");
	$("#Executable_flip").slideUp("slow");
	$("#SVCP_flip").slideUp("slow");
	$("#SVR_flip").slideUp("slow");
	$("#SECI_flip").slideUp("slow");
	$("#SCI_flip").slideUp("slow");
	$("#Problems_flip").slideUp("slow");
	$("#Configs_flip").slideUp("slow");
	$("#QA_flip").slideUp("slow");
	$("#SAS_flip").slideUp("slow");
  });
  $("#Executable").click(function(){
    $("#PSAC_flip").slideUp("slow");
	$("#SDP_flip").slideUp("slow");
	$("#SVP_flip").slideUp("slow");
	$("#SCMP_flip").slideUp("slow");
	$("#SQAP_flip").slideUp("slow");
	$("#SRS_flip").slideUp("slow");
	$("#SDS_flip").slideUp("slow");
	$("#SCS_flip").slideUp("slow");
	$("#SRD_flip").slideUp("slow");
	$("#SDD_flip").slideUp("slow");
	$("#Source_flip").slideUp("slow");
	$("#Executable_flip").slideToggle("slow");
	$("#SVCP_flip").slideUp("slow");
	$("#SVR_flip").slideUp("slow");
	$("#SECI_flip").slideUp("slow");
	$("#SCI_flip").slideUp("slow");
	$("#Problems_flip").slideUp("slow");
	$("#Configs_flip").slideUp("slow");
	$("#QA_flip").slideUp("slow");
	$("#SAS_flip").slideUp("slow");
  });
  $("#SVCP").click(function(){
    $("#PSAC_flip").slideUp("slow");
	$("#SDP_flip").slideUp("slow");
	$("#SVP_flip").slideUp("slow");
	$("#SCMP_flip").slideUp("slow");
	$("#SQAP_flip").slideUp("slow");
	$("#SRS_flip").slideUp("slow");
	$("#SDS_flip").slideUp("slow");
	$("#SCS_flip").slideUp("slow");
	$("#SRD_flip").slideUp("slow");
	$("#SDD_flip").slideUp("slow");
	$("#Source_flip").slideUp("slow");
	$("#Executable_flip").slideUp("slow");
	$("#SVCP_flip").slideToggle("slow");
	$("#SVR_flip").slideUp("slow");
	$("#SECI_flip").slideUp("slow");
	$("#SCI_flip").slideUp("slow");
	$("#Problems_flip").slideUp("slow");
	$("#Configs_flip").slideUp("slow");
	$("#QA_flip").slideUp("slow");
	$("#SAS_flip").slideUp("slow");
  });
  $("#SVR").click(function(){
    $("#PSAC_flip").slideUp("slow");
	$("#SDP_flip").slideUp("slow");
	$("#SVP_flip").slideUp("slow");
	$("#SCMP_flip").slideUp("slow");
	$("#SQAP_flip").slideUp("slow");
	$("#SRS_flip").slideUp("slow");
	$("#SDS_flip").slideUp("slow");
	$("#SCS_flip").slideUp("slow");
	$("#SRD_flip").slideUp("slow");
	$("#SDD_flip").slideUp("slow");
	$("#Source_flip").slideUp("slow");
	$("#Executable_flip").slideUp("slow");
	$("#SVCP_flip").slideUp("slow");
	$("#SVR_flip").slideToggle("slow");
	$("#SECI_flip").slideUp("slow");
	$("#SCI_flip").slideUp("slow");
	$("#Problems_flip").slideUp("slow");
	$("#Configs_flip").slideUp("slow");
	$("#QA_flip").slideUp("slow");
	$("#SAS_flip").slideUp("slow");
  });
  $("#SECI").click(function(){
    $("#PSAC_flip").slideUp("slow");
	$("#SDP_flip").slideUp("slow");
	$("#SVP_flip").slideUp("slow");
	$("#SCMP_flip").slideUp("slow");
	$("#SQAP_flip").slideUp("slow");
	$("#SRS_flip").slideUp("slow");
	$("#SDS_flip").slideUp("slow");
	$("#SCS_flip").slideUp("slow");
	$("#SRD_flip").slideUp("slow");
	$("#SDD_flip").slideUp("slow");
	$("#Source_flip").slideUp("slow");
	$("#Executable_flip").slideUp("slow");
	$("#SVCP_flip").slideUp("slow");
	$("#SVR_flip").slideUp("slow");
	$("#SECI_flip").slideToggle("slow");
	$("#SCI_flip").slideUp("slow");
	$("#Problems_flip").slideUp("slow");
	$("#Configs_flip").slideUp("slow");
	$("#QA_flip").slideUp("slow");
	$("#SAS_flip").slideUp("slow");
  });
  $("#SCI").click(function(){
    $("#PSAC_flip").slideUp("slow");
	$("#SDP_flip").slideUp("slow");
	$("#SVP_flip").slideUp("slow");
	$("#SCMP_flip").slideUp("slow");
	$("#SQAP_flip").slideUp("slow");
	$("#SRS_flip").slideUp("slow");
	$("#SDS_flip").slideUp("slow");
	$("#SCS_flip").slideUp("slow");
	$("#SRD_flip").slideUp("slow");
	$("#SDD_flip").slideUp("slow");
	$("#Source_flip").slideUp("slow");
	$("#Executable_flip").slideUp("slow");
	$("#SVCP_flip").slideUp("slow");
	$("#SVR_flip").slideUp("slow");
	$("#SECI_flip").slideUp("slow");
	$("#SCI_flip").slideToggle("slow");
	$("#Problems_flip").slideUp("slow");
	$("#Configs_flip").slideUp("slow");
	$("#QA_flip").slideUp("slow");
	$("#SAS_flip").slideUp("slow");
  });
  $("#Problems").click(function(){
    $("#PSAC_flip").slideUp("slow");
	$("#SDP_flip").slideUp("slow");
	$("#SVP_flip").slideUp("slow");
	$("#SCMP_flip").slideUp("slow");
	$("#SQAP_flip").slideUp("slow");
	$("#SRS_flip").slideUp("slow");
	$("#SDS_flip").slideUp("slow");
	$("#SCS_flip").slideUp("slow");
	$("#SRD_flip").slideUp("slow");
	$("#SDD_flip").slideUp("slow");
	$("#Source_flip").slideUp("slow");
	$("#Executable_flip").slideUp("slow");
	$("#SVCP_flip").slideUp("slow");
	$("#SVR_flip").slideUp("slow");
	$("#SECI_flip").slideUp("slow");
	$("#SCI_flip").slideUp("slow");
	$("#Problems_flip").slideToggle("slow");
	$("#Configs_flip").slideUp("slow");
	$("#QA_flip").slideUp("slow");
	$("#SAS_flip").slideUp("slow");
  });
  $("#Configs").click(function(){
    $("#PSAC_flip").slideUp("slow");
	$("#SDP_flip").slideUp("slow");
	$("#SVP_flip").slideUp("slow");
	$("#SCMP_flip").slideUp("slow");
	$("#SQAP_flip").slideUp("slow");
	$("#SRS_flip").slideUp("slow");
	$("#SDS_flip").slideUp("slow");
	$("#SCS_flip").slideUp("slow");
	$("#SRD_flip").slideUp("slow");
	$("#SDD_flip").slideUp("slow");
	$("#Source_flip").slideUp("slow");
	$("#Executable_flip").slideUp("slow");
	$("#SVCP_flip").slideUp("slow");
	$("#SVR_flip").slideUp("slow");
	$("#SECI_flip").slideUp("slow");
	$("#SCI_flip").slideUp("slow");
	$("#Problems_flip").slideUp("slow");
	$("#Configs_flip").slideToggle("slow");
	$("#QA_flip").slideUp("slow");
	$("#SAS_flip").slideUp("slow");
  });
  $("#QA").click(function(){
    $("#PSAC_flip").slideUp("slow");
	$("#SDP_flip").slideUp("slow");
	$("#SVP_flip").slideUp("slow");
	$("#SCMP_flip").slideUp("slow");
	$("#SQAP_flip").slideUp("slow");
	$("#SRS_flip").slideUp("slow");
	$("#SDS_flip").slideUp("slow");
	$("#SCS_flip").slideUp("slow");
	$("#SRD_flip").slideUp("slow");
	$("#SDD_flip").slideUp("slow");
	$("#Source_flip").slideUp("slow");
	$("#Executable_flip").slideUp("slow");
	$("#SVCP_flip").slideUp("slow");
	$("#SVR_flip").slideUp("slow");
	$("#SECI_flip").slideUp("slow");
	$("#SCI_flip").slideUp("slow");
	$("#Problems_flip").slideUp("slow");
	$("#Configs_flip").slideUp("slow");
	$("#QA_flip").slideToggle("slow");
	$("#SAS_flip").slideUp("slow");
  });
  $("#SAS").click(function(){
    $("#PSAC_flip").slideUp("slow");
	$("#SDP_flip").slideUp("slow");
	$("#SVP_flip").slideUp("slow");
	$("#SCMP_flip").slideUp("slow");
	$("#SQAP_flip").slideUp("slow");
	$("#SRS_flip").slideUp("slow");
	$("#SDS_flip").slideUp("slow");
	$("#SCS_flip").slideUp("slow");
	$("#SRD_flip").slideUp("slow");
	$("#SDD_flip").slideUp("slow");
	$("#Source_flip").slideUp("slow");
	$("#Executable_flip").slideUp("slow");
	$("#SVCP_flip").slideUp("slow");
	$("#SVR_flip").slideUp("slow");
	$("#SECI_flip").slideUp("slow");
	$("#SCI_flip").slideUp("slow");
	$("#Problems_flip").slideUp("slow");
	$("#Configs_flip").slideUp("slow");
	$("#QA_flip").slideUp("slow");
	$("#SAS_flip").slideToggle("slow");
  });
	
});
</script>
</head>
<body>

<form>
  <div id="radio">
    <input type="radio" id="levelA" name="radio" /> <label for="levelA">Level A</label>
    <input type="radio" id="levelB" name="radio" /> <label for="levelB">Level B</label>
    <input type="radio" id="levelC" name="radio" /> <label for="levelC">Level C</label>
	<input type="radio" id="levelD" name="radio" /> <label for="levelD">Level D</label>
	<input type="radio" id="levelE" name="radio" /> <label for="levelE">Level E</label>
  </div>
</form>


<style> 
#PSAC,#SDP,#SVP,#SCMP,#SQAP,#SRS,#SDS,#SCS,#SRD,#SDD,#Source,#Executable,#SVCP,#SVR,#SECI,#SCI,#Problems,#Configs,#QA,#SAS,#PSAC_flip,#SDP_flip,#SVP_flip,#SCMP_flip,#SQAP_flip,#SRS_flip,#SDS_flip,#SCS_flip,#SRD_flip,#SDD_flip,#Source_flip,#Executable_flip,#SVCP_flip,#SVR_flip,#SECI_flip,#SCI_flip,#Problems_flip,#Configs_flip,#QA_flip,#SAS_flip
{
padding:1px;
text-align:left;
background-color:lightgrey;
border:solid 1px black;
}

#PSAC_flip,#SDP_flip,#SVP_flip,#SCMP_flip,#SQAP_flip,#SRS_flip,#SDS_flip,#SCS_flip,#SRD_flip,#SDD_flip,#Source_flip,#Executable_flip,#SVCP_flip,#SVR_flip,#SECI_flip,#SCI_flip,#Problems_flip,#Configs_flip,#QA_flip,#SAS_flip 
{
text-align:center;
padding:5px;
display:none;
border:solid 1px black;
}

#PSAC_indep,#SDP_indep,#SVP_indep,#SCMP_indep,#SQAP_indep,#SRS_indep,#SDS_indep,#SCS_indep,#SRD_indep,#SDD_indep,#Source_indep,#Executable_indep,#SVCP_indep,#SVR_indep,#SECI_indep,#SCI_indep,#Problems_indep,#Configs_indep,#QA_indep,#SAS_indep,#PSAC_obj,#SDP_obj,#SVP_obj,#SCMP_obj,#SQAP_obj,#SRS_obj,#SDS_obj,#SCS_obj,#SRD_obj,#SDD_obj,#Source_obj,#Executable_obj,#SVCP_obj,#SVR_obj,#SECI_obj,#SCI_obj,#Problems_obj,#Configs_obj,#QA_obj,#SAS_obj,#Heading
{
padding:1px;
text-align:center;
background-color:lightgrey;
border:solid 1px black;
}


</style>
</body>
</html>

<table style="width:100%">
  <tr>
    <td><div id="Heading">Deliverable</div></td>
    <td><div id="Heading">Independent</div></td> 
    <td><div id="Heading">Objectives</div></td>
  </tr>

  <tr>
    <td><div id="PSAC">- Plan for Software Aspects of Certification (PSAC)</div></td>
    <td><div id="PSAC_indep">-</div></td> 
    <td><div id="PSAC_obj">-</div></td>
  </tr>
  <tr>
	<td colspan="3">
	<div id="PSAC_flip">
	The Plan for Software Aspects of Certification is the primary means used by the certification authority for determining whether an applicant is proposing a software life cycle that is commensurate with the rigor required for the level of software being developed.
	</div>
	</td>
  </tr>

  <tr>
    <td><div id="SDP">- Software Development Plan (SDP)</div></td>
    <td><div id="SDP_indep">-</div></td> 
    <td><div id="SDP_obj">-</div></td>
  </tr>
  <tr>
	<td colspan="3">
	<div id="SDP_flip">
	The Software Development Plan includes the objectives, standards and software life cycle(s) to be used in the software development processes.
	</div>
	</td>
  </tr>


  <tr>
    <td><div id="SVP">- Software Verification Plan (SVP)</div></td>
	<td><div id="SVP_indep">-</div></td> 
    <td><div id="SVP_obj">-</div></td>
  </tr>
  <tr>
	<td colspan="3">
	<div id="SVP_flip">&#8220;The Software Verification Plan is a description of the verification procedures to satisfy the software verification process objectives.
	</div>
	</td>
  </tr>

  <tr>
    <td><div id="SCMP">- Software Configuration Management Plan (SCMP)</div></td>
	<td><div id="SCMP_indep">-</div></td> 
    <td><div id="SCMP_obj">-</div></td>
  </tr>
  <tr>
	<td colspan="3">
	<div id="SCMP_flip">The Software Configuration Management Plan establishes the methods to be used to achieve the objectives of the software configuration management (SCM) process throughout the software life cycle.
	</div>
	</td>
  </tr>

  <tr>
    <td><div id="SQAP">- Software Quality Assurance Plan (SQAP)</div></td>
	<td><div id="SQAP_indep">-</div></td> 
    <td><div id="SQAP_obj">-</div></td>
  </tr>
  <tr>
	<td colspan="3">
	<div id="SQAP_flip">The Software Quality Assurance Plan establishes the methods to be used to achieve the objectives of the software quality assurance (SQA) process. The SQA Plan may include descriptions of process improvement, metrics, and progressive management methods.
    </div>
	</td>
  </tr>

  <tr>
    <td><div id="SRS">- Software Requirements Standards (SRS)</div></td>
	<td><div id="SRS_indep">-</div></td> 
    <td><div id="SRS_obj">-</div></td>
  </tr>
  <tr>
	<td colspan="3">
	<div id="SRS_flip">The purpose of Software Requirements Standards is to define the methods, rules and tools to be used to develop the high-level requirements.
    </div>
	</td>
  </tr>

  <tr>
    <td><div id="SDS">- Software Design Standards (SDS)</div></td>
	<td><div id="SDS_indep">-</div></td> 
    <td><div id="SDS_obj">-</div></td>
  </tr>
  <tr>
	<td colspan="3">
	<div id="SDS_flip">The purpose of Software Design Standards is to define the methods, rules and tools to be used to develop the software architecture and low-level requirements.
    </div>
	</td>
  </tr>

  <tr>
    <td><div id="SCS">- Software Code Standards	(SCS)</div></td>
	<td><div id="SCS_indep">-</div></td> 
    <td><div id="SCS_obj">-</div></td>
  </tr>
  <tr>
	<td colspan="3">
	<div id="SCS_flip">The purpose of the Software Code Standards is to define the programming languages, methods, rules and tools to be used to code the software.
	</div>
	</td>
  </tr>

  <tr>
    <td><div id="SRD">- Software Requirements Data (SRD)</div></td>
	<td><div id="SRD_indep">-</div></td> 
    <td><div id="SRD_obj">-</div></td>
  </tr>
  <tr>
	<td colspan="3">
	<div id="SRD_flip">Software Requirements Data is a definition of the high-level requirements including the derived requirements.
	</div>
	</td>
  </tr>

  <tr>
    <td><div id="SDD">- Software Design Description (SDD)</div></td>
	<td><div id="SDD_indep">-</div></td> 
    <td><div id="SDD_obj">-</div></td>
  </tr>
  <tr>
	<td colspan="3">
	<div id="SDD_flip">The Design Description is a definition of the software architecture and the low-level requirements that will satisfy the software high-level requirements.
	</div>
	</td>
  </tr>

  <tr>
    <td><div id="Source">- Source Code</div></td>
	<td><div id="Source_indep">-</div></td> 
    <td><div id="Source_obj">-</div></td>
  </tr>
  <tr>
	<td colspan="3">
	<div id="Source_flip">This data consists of code written in source language(s) and the compiler instructions for generating the object code from the Source Code, and linking and loading data. This data should include the software identification, including the name and date of revision and/or version, as applicable.
	</div>
	</td>
  </tr>

  <tr>
    <td><div id="Executable">- Executable Object Code</div></td>
	<td><div id="Executable_indep">-</div></td> 
    <td><div id="Executable_obj">-</div></td>
  </tr>
  <tr>
	<td colspan="3">
	<div id="Executable_flip">The Executable Object Code consists of a form of Source Code that is directly usable by the central processing unit of the target computer and is, therefore, the software that is loaded into the hardware or system.
	</div>
	</td>
  </tr>

  <tr>
    <td><div id="SVCP">- Software Verification Cases and Procedures (SVCP)</div></td>
	<td><div id="SVCP_indep">-</div></td> 
    <td><div id="SVCP_obj">-</div></td>
  </tr>
  <tr>
	<td colspan="3">
	<div id="SVCP_flip">Software Verification Cases and Procedures detail how the software verification process activities are implemented.
	</div>
	</td>
  </tr>

  <tr>
    <td><div id="SVR">- Software Verification Results (SVR)</div></td>
	<td><div id="SVR_indep">-</div></td> 
    <td><div id="SVR_obj">-</div></td>
  </tr>
  <tr>
	<td colspan="3">
	<div id="SVR_flip">The Software Verification Results are produced by the software verification process activities.
	</div>
	</td>
  </tr>

  <tr>
    <td><div id="SECI">- Software Life Cycle Environment Configuration Index (SECI)</div></td>
	<td><div id="SECI_indep">-</div></td> 
    <td><div id="SECI_obj">-</div></td>
  </tr>
  <tr>
	<td colspan="3">
	<div id="SECI_flip">The Software Life Cycle Environment Configuration Index (SECI) identifies the configuration of the software life cycle environment. This index is written to aid reproduction of the hardware and software life cycle environment, for software regeneration, reverification, or software modification.
	</div>
	</td>
  </tr>

  <tr>
    <td><div id="SCI">- Software Configuration Index (SCI)</div></td>
	<td><div id="SCI_indep">-</div></td> 
    <td><div id="SCI_obj">-</div></td>
  </tr>
  <tr>
	<td colspan="3">
	<div id="SCI_flip">The Software Configuration Index (SCI) identifies the configuration of the software product.
	</div>
	</td>
  </tr>

  <tr>
    <td><div id="Problems">- Problem Reports</div></td>
	<td><div id="Problems_indep">-</div></td> 
    <td><div id="Problems_obj">-</div></td>
  </tr>
  <tr>
	<td colspan="3">
	<div id="Problems_flip">Problem reports are a means to identify and record the resolution to software product anomalous behavior, process non-compliance with software plans and standards, and deficiencies in software life cycle data.
	</div>
	</td>
  </tr>

  <tr>
    <td><div id="Configs">- Software Configuration Management Records</div></td>
	<td><div id="Configs_indep">-</div></td> 
    <td><div id="Configs_obj">-</div></td>
  </tr>
  <tr>
	<td colspan="3">
	<div id="Configs_flip">The results of the SCM process activities are recorded in SCM Records. Examples include configuration identification lists, baseline or software library records, change history reports, archive records, and release records.
    </div>
	</td>
  </tr>

  <tr>
    <td><div id="QA">- Software Quality Assurance Records</div></td>
	<td><div id="QA_indep">-</div></td> 
    <td><div id="QA_obj">-</div></td>
  </tr>
  <tr>
	<td colspan="3">
	<div id="QA_flip">The results of the SQA process activities are recorded in SQA Records. These may include SQA review or audit reports, meeting minutes, records of authorized process deviations, or software conformity review records.
    </div>
	</td>
  </tr>

  <tr>
    <td><div id="SAS">- Software Accomplishment Summary (SAS)</div></td>
	<td><div id="SAS_indep">-</div></td> 
    <td><div id="SAS_obj">-</div></td>
  </tr>
  <tr>
	<td colspan="3">
	<div id="SAS_flip">The Software Accomplishment Summary is the primary data item for showing compliance with the Plan for Software Aspects of Certification.
    </div>
	</td>
  </tr>
</table>

<p><br />
That’s a lot of dead trees…</p>

<p>An objective is typically something like the “Software development standards are defined” or “High level requirements are verifiable”. So it is still fairly open for interpretation by the developers and the certification body. I’ll go into more detail of each objective when considering how DO-178 can be made more <a href="http://embeddedfool.net/blog/2015/01/12/a-more-agile-do-178/">agile</a>. (Observant readers will notice the total objectives does not equal those reported in the criticality table, that is because some objectives has to be included in multiple documents and so I counted them twice).</p>

<p>Where objectives are marked independent, it means an independent authority has to verify conformance. For this purpose quite a few consultants in the business earn their keep by evaluating compliance independently.</p>

<h2>Software development process</h2>
<p>DO-178B prescribes the following software development process:</p>

<ul>
  <li>Software requirements process</li>
  <li>Software design process</li>
  <li>Software development process</li>
  <li>Integration process</li>
</ul>

<p>Typically for DO-178B this is implemented through the <a href="http://en.wikipedia.org/wiki/V-Model_%28software_development%29">V-model</a> in systems engineering, also somewhat equivalent to the <a href="http://en.wikipedia.org/wiki/Waterfall_model">waterfall method</a> in software development. </p>

<p>(Note this is nowhere specified in the DO-178 specification, but is what I have typically observed happens on DO-178 projects).</p>

<p><img class="center" src="http://embeddedfool.net/images/vee_plot.png" width="600" /></p>

<h4>Traceability</h4>
<p>Traceability’s purpose is two-fold. First is to make sure the design takes into account all the requirements set for the project. Requirements which has not been taken into account by the design are called childless requirements.</p>

<p>Traceability analysis must also make sure there are no additional and unneeded requirements introduced during design, as these would unnecessarily escalate the development costs. These are called orphan requirements. But it is understood that some requirements may be derived from the design decisions made and is thus not traceable to the user requirements. These additional requirements must be taken into consideration when analyzing their safety effects on the system.   </p>

<p>For these reasons most of the documentation listed above will contain a traceability matrix towards the end of the document, indicating the parent of each requirement.</p>

<h4>Verification</h4>
<p>Verification is concerned with if the development is being implemented correctly according to the design, and if the integration is done correctly as designed and developed i.e. “Are we building this correctly”</p>

<p>Verification for DO-178B consists of two steps, namely requirements based coverage analysis where it is checked that all requirements are satisfied and tested, and also structural coverage analysis where it is checked that during testing all code paths are executed, so there is no untested code in the final product.</p>

<p>Lastly as part of the verification process DO-178B requires that no dead code be present in the final binary and that de-activated code (perhaps code used in another configuration of the product) cannot be accidentally executed.</p>

<p>For these reasons code coverage tests is required for the various levels in DO-178:</p>

<ul>
  <li>Level A requires <a href="http://en.wikipedia.org/wiki/Modified_condition/decision_coverage">Modified Condition Decision Coverage (MCDC)</a></li>
  <li>Level B requires decision coverage.</li>
  <li>Level C requires coverage of dependencies.</li>
  <li>Level D and E requires no code coverage verification.</li>
</ul>

<h4>Validation</h4>
<p>Validation is concerned with if the final product satisfies the intended use of the product i.e. “Did we build the right thing” or “Does this product actually work”. Sometimes this is not the case.</p>

<h2>Odds and ends</h2>
<p>DO-178B does not mandate the development process to be followed, but does focus quite a bit on the supporting functions to the development process. These include configuration management, quality assurance, certification liaison and software verification.</p>

<p>DO-178B lists two control categories according to which every deliverable must be configured. Control category 1 has for instance requirements such as “Protection against unauthorized changes”, “Change review” etc. Control category 2 is a relaxed list of Control category 1. As such Level A certification mandates more items be configured according to the requirements of Control Category 1, whereas the lower levels allows more items under Control Category 2. Control Category 1 can be a real pain in the …</p>

<p>DO-178B also focuses quite a bit on the reproducibility of the executable from the source code and ensuring its correctness. As such any tools used to produce the executable should be under configuration management, and if possible the tools (such as the compiler) should also be DO-178 certified. This also applies to off the shelve software components used with the developed software, and is the reason you get some DO-178 certified RTOS (real time operating systems) these days. Good luck getting a DO-178 certified compiler though… </p>

<p>Where these tools and off the shelve components do not conform to DO-178 requirements, a gap analysis should be done to determine the effort that would be required in certifying the tool or off the shelve software to DO-178. A great many times it is determined to be cheaper to develop the functionality of the tool or software component in house than to attempt to certify the already existing item.</p>

<h4>A word about documentation conventions</h4>

<p>DO-178B does not specify the documentation standard to be followed, but most projects do follow some or other documentation standard. The following figure is loosely based on <a href="http://en.wikipedia.org/wiki/MIL-STD-498">MIL-STD-490A</a>, although sometimes “Detail design” and “Notes” are changed into some other topic of discussion.</p>

<p><img class="center" src="http://embeddedfool.net/images/documents.png" width="600" /></p>

<p>In the documentation, especially when talking about requirements and specifications, certain words convey additional meaning apart from their linguistic use. These words are usually capitalized.</p>

<p><strong><em>SHALL</em></strong> and <strong><em>SHALL</em> <em>NOT</em></strong> - Indicates a mandatory requirement.</p>

<p><strong><em>WILL</em></strong> and <strong><em>WILL NOT</em></strong> - Indicates a declaration of purpose or an expression of simple futurity.</p>

<p><strong><em>SHOULD</em></strong> and <strong><em>SHOULD NOT</em></strong> - Indicates a non-mandatory desire, preference or recommendation.</p>

<p><strong><em>MAY</em></strong> and <strong><em>MAY NOT</em></strong> - Indicates a non-mandatory suggestion or permission.</p>

<p><strong><em>MUST</em></strong> and <strong><em>MUST NOT</em></strong> should be avoided as it causes confusion with the above terms. </p>

<p>That concludes this overview of DO-178B. It is certainly not an exhaustive analysis of DO-178B, for that you might just as well read the specification, but should prove sufficient to get students started implementing a DO-178 certified project.</p>

<p>If I have missed anything or you would like to make a suggestion, kindly do so at the discussion on <a href="https://news.ycombinator.com/item?id=8937549">HN</a> and <a href="http://www.reddit.com/r/programming/comments/2tg71e/do178b_crash_course/">reddit</a>. Comments and suggestions are very welcome.</p>

<p>I will be drilling more into DO-178, especially the 66 objectives mentioned earlier in my post <a href="">A more agile DO-178 (TBC)</a>. Stay tuned. </p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Slow Bugs]]></title>
    <link href="http://embeddedfool.net/blog/2014/12/27/slow-bugs/"/>
    <updated>2014-12-27T12:00:00+02:00</updated>
    <id>http://embeddedfool.net/blog/2014/12/27/slow-bugs</id>
    <content type="html"><![CDATA[<p>A slow bug is one which requires substantial testing to show itself. Recently we had such a bug, which required roughly 8 hours of testing, and if you’re lucky, you’ll see it once. Horrible stuff…</p>

<p>This makes for extremely slow debug cycles, almost going back to the batch programming mainframe days where you <a href="http://www.embedded.com/electronics-blogs/break-points/4437958/On-engineering-notebooks">run code in your head</a> and hypothesise what the code is actually doing. It turned out our bug in this case had nothing to do with a fault in the code, but noise getting picked up on one of the JTAG select lines. Unfortunately we didn’t start by looking at the JTAG lines… </p>

<p>Once we had settled on this hypotheses, and implemented a fix, the question became how long should one test before you are satisfied the bug is fixed. How long before you are 99% sure, 99.9% sure, 99.999% sure?</p>

<p><img class="right" src="http://embeddedfool.net/images/uniform_distribution.png" width="300" title="uniform distribution bugs" />
Thinking about this problem got me thinking about bug probabilities and of how they might manifest. I theorised three types of bugs. First is bugs with a unity probability distribution function, that is it is equally likely to occur at any time during the testing procedure. This is applicable for a huge class of bugs, most importantly for bugs which doesn’t have memory. So timing bugs, race conditions, noise induced bugs etc. all fit the bill.<br />
<br />
<br />
<br /></p>

<p><img class="right" src="http://embeddedfool.net/images/increasing_distribution.png" width="300" title="increasing distribution bugs" />
This is in contrast to bugs with memory, where the longer you test the more likely it is that you’ll encounter the bug. This could be memory leaks, heap fragmentation or in some cases state machine bugs. These bugs represents an interesting dilemma for us, which I’ll get back to later.<br />
<br />
<br />
<br />
<br />
<br /></p>

<p><img class="right" src="http://embeddedfool.net/images/decreasing_distribution.png" width="300" title="decreasing distribution bugs" />
Looking at the previous two plots, I wondered if there were bugs with the following graph, bugs which will manifest early, but become less likely to manifest the longer the system runs. And it dawned on me you do get bugs like this, namely system start-up and initialization bugs. Once the system is running, it is stable, but if you reboot it many times over, every now and then the reboot will fail.
<br />
<br />
<br />
<br /></p>

<p>Focussing on the uniform distribution bugs, we can think of the probability of encountering a bug as a <a href="http://en.wikipedia.org/wiki/Poisson_distribution">Poisson distribution</a>. More specifically, if we encountered on average $ \frac{1}{8} $ bugs every hour, then the probability mass function of our Poisson distribution looks as follows:</p>

<script type="math/tex; mode=display"> f(x) = \frac{e^{- \lambda}\lambda^x}{x!} \tag{Poisson distribution}</script>

<script type="math/tex; mode=display">\lambda = \frac{1}{8} \tag{1 bug every 8 hours}</script>

<p>That’s great and all if we wanted to know how many times we’ll see a bug while testing, but we want to know how long should we test to be sure the bug is gone (There’s a subtle difference). To calculate this we need the cumulative distribution function of f(x), i.e.</p>

<script type="math/tex; mode=display">% &lt;![CDATA[
 F(x) = P(X <= x) = \int_{-\infty}^x f(u) \delta u %]]&gt;</script>

<p>This result has a exponential distribution:</p>

<script type="math/tex; mode=display"> f(x) = \lambda e^{- \lambda x} \tag{Cumulative distribution}</script>

<p>Then to calculate the amount of testing required for your confidence of say 99% we need to take the area under curve as shown:</p>

<p><img class="center" src="http://embeddedfool.net/images/cumulative_distribution.png" width="300" /></p>

<script type="math/tex; mode=display"> P(X > x) = \int_x^\infty \frac{1}{8}e^{-\frac{1}{8}x} = 1 - 0.99 </script>

<script type="math/tex; mode=display"> P(X > x) = e^{-\frac{1}{8}x} = 0.01</script>

<p>This gives us the following answer (I calculated for 99.9% and 99.999% as well)</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\begin{array}{c|lcr}
P(X > x) & \text{Hours} & \text{Bug mean} & \text{Factor} \\
\hline
99\% & 36.8 & 8 & 5 \\
99.9\% & 55.3 & 8 & 7 \\
99.999\% & 92.1 & 8 & 12
\end{array}
 %]]&gt;</script>

<p>So this is quite interesting, to be 99% certain you have solved your bug, you need to test about 5 times longer than it would normally take for the bug to manifest. I know of many times where I only tested about 2 times longer and called the bug fixed with great confidence. For interest sake, if you only test 2 times longer, you can only be 22% confident your bug is fixed!!</p>

<p>Ok great so that answers our initial question, but what about the other types of bugs? Well for the third class of bugs i.e. start-up bugs, it is sufficient to think not in term of how many hours you need to run the test, but rather how many times you should run the test (reboot the system). Then this class of bug look exactly the same as the uniform distribution bug, and can be solved in much the same way, but instead of hours you get the amount of test iterations you should run. </p>

<p>Now I said the increasing probability bugs represents an interesting dilemma, and that is because they do not represent an Poisson distribution. Rather no amount of testing will adequately prove to any confidence level that you have solved the bug. These kind of bugs are in essence known as the <a href="http://en.wikipedia.org/wiki/Halting_problem">halting problem</a> in computer science. Unfortunately that one has already been proved unsolvable…</p>

<p>Ok so my stats was never that great, I had some help from my old statistics handbook:
Engineering Statistics Montgommery et al.</p>

<p>*Also please note that this is not in any way supposed to be a rigorous statistical analysis.</p>
]]></content>
  </entry>
  
</feed>
